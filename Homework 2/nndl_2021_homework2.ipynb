{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm import tqdm # this module is useful to plot progress bars\n",
    "\n",
    "#import plotly_express as px #plotly_express = \"0.4.0\"\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download the data and create dataset\n",
    "data_dir = 'dataset'\n",
    "# With these commands the train and test datasets, respectively, are downloaded \n",
    "# automatically and stored in the local \"data_dir\" directory.\n",
    "train_dataset = torchvision.datasets.FashionMNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.FashionMNIST(data_dir, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "lr = 5e-4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data transform to tensors and define dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN BATCH SHAPE\n",
      "\t Data: torch.Size([256, 1, 28, 28])\n",
      "\t Labels: torch.Size([256])\n",
      "TEST BATCH SHAPE\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "\t Data: torch.Size([256, 1, 28, 28])\n",
      "\t Labels: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_dataset.transform = transform\n",
    "test_dataset.transform = transform\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "batch_data, batch_labels = next(iter(train_dataloader))\n",
    "print(f\"TRAIN BATCH SHAPE\")\n",
    "print(f\"\\t Data: {batch_data.shape}\")# 256 batch size 1  28*28 size of pics\n",
    "print(f\"\\t Labels: {batch_labels.shape}\")\n",
    "\n",
    "batch_data, batch_labels = next(iter(test_dataloader))\n",
    "print(f\"TEST BATCH SHAPE\")\n",
    "print(type(batch_data))\n",
    "print(type(batch_labels))\n",
    "print(f\"\\t Data: {batch_data.shape}\")\n",
    "print(f\"\\t Labels: {batch_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "###encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, \n",
    "                      stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, \n",
    "                      stride=2, padding=1), \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, \n",
    "                      stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(in_features=3*3*32, out_features=64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_features=64, out_features=encoded_space_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "###decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(in_features = encoded_space_dim, out_features=64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(in_features=64,out_features=3*3*32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1,unflattened_size=(32, 3, 3))\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, \n",
    "                               stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1)\n",
    "            \n",
    "                            \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(encoded_space_dim)\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(encoded_space_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        codes = self.encoder(inputs)\n",
    "        decoded = self.decoder(codes)\n",
    "        return codes, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize the two networks\n",
    "\n",
    "# Set the random seed for reproducible results\n",
    "torch.manual_seed(2041389)\n",
    "\n",
    "# Initialize the two networks\n",
    "encoded_space_dim = 2\n",
    "encoder = Encoder(encoded_space_dim=encoded_space_dim)\n",
    "decoder = Decoder(encoded_space_dim=encoded_space_dim)\n",
    "model_AE = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_lin): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=288, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (unflatten): Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ConvTranspose2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training function and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    for image_batch, _ in dataloader:\n",
    "        image_batch = image_batch.to(device)\n",
    "        encoded_data = encoder(image_batch)\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        loss = loss_fn(decoded_data, image_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('\\t partial train loss (single batch): %f' % (loss.data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(encoder,decoder,dataloader,loss_fn,device):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    conc_out = []\n",
    "    conc_label = []\n",
    "    for image_batch, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "    # Create a single tensor with all the values in the lists\n",
    "    conc_out = torch.cat(conc_out)\n",
    "    conc_label = torch.cat(conc_label) \n",
    "    # Evaluate global loss\n",
    "    val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/10\n",
      "\t partial train loss (single batch): 0.148648\n",
      "\t partial train loss (single batch): 0.144547\n",
      "\t partial train loss (single batch): 0.149319\n",
      "\t partial train loss (single batch): 0.146885\n",
      "\t partial train loss (single batch): 0.146311\n",
      "\t partial train loss (single batch): 0.145706\n",
      "\t partial train loss (single batch): 0.149413\n",
      "\t partial train loss (single batch): 0.149691\n",
      "\t partial train loss (single batch): 0.150210\n",
      "\t partial train loss (single batch): 0.150495\n",
      "\t partial train loss (single batch): 0.147734\n",
      "\t partial train loss (single batch): 0.147185\n",
      "\t partial train loss (single batch): 0.147033\n",
      "\t partial train loss (single batch): 0.146800\n",
      "\t partial train loss (single batch): 0.143766\n",
      "\t partial train loss (single batch): 0.146604\n",
      "\t partial train loss (single batch): 0.148034\n",
      "\t partial train loss (single batch): 0.147854\n",
      "\t partial train loss (single batch): 0.149754\n",
      "\t partial train loss (single batch): 0.146046\n",
      "\t partial train loss (single batch): 0.142227\n",
      "\t partial train loss (single batch): 0.141467\n",
      "\t partial train loss (single batch): 0.145580\n",
      "\t partial train loss (single batch): 0.145269\n",
      "\t partial train loss (single batch): 0.141688\n",
      "\t partial train loss (single batch): 0.146502\n",
      "\t partial train loss (single batch): 0.146822\n",
      "\t partial train loss (single batch): 0.145624\n",
      "\t partial train loss (single batch): 0.145615\n",
      "\t partial train loss (single batch): 0.142875\n",
      "\t partial train loss (single batch): 0.146084\n",
      "\t partial train loss (single batch): 0.143340\n",
      "\t partial train loss (single batch): 0.140636\n",
      "\t partial train loss (single batch): 0.144698\n",
      "\t partial train loss (single batch): 0.142048\n",
      "\t partial train loss (single batch): 0.143754\n",
      "\t partial train loss (single batch): 0.142932\n",
      "\t partial train loss (single batch): 0.139050\n",
      "\t partial train loss (single batch): 0.139615\n",
      "\t partial train loss (single batch): 0.144442\n",
      "\t partial train loss (single batch): 0.138951\n",
      "\t partial train loss (single batch): 0.138743\n",
      "\t partial train loss (single batch): 0.138367\n",
      "\t partial train loss (single batch): 0.137809\n",
      "\t partial train loss (single batch): 0.138906\n",
      "\t partial train loss (single batch): 0.138128\n",
      "\t partial train loss (single batch): 0.137606\n",
      "\t partial train loss (single batch): 0.134456\n",
      "\t partial train loss (single batch): 0.129555\n",
      "\t partial train loss (single batch): 0.131934\n",
      "\t partial train loss (single batch): 0.134720\n",
      "\t partial train loss (single batch): 0.134816\n",
      "\t partial train loss (single batch): 0.130688\n",
      "\t partial train loss (single batch): 0.129716\n",
      "\t partial train loss (single batch): 0.127154\n",
      "\t partial train loss (single batch): 0.123981\n",
      "\t partial train loss (single batch): 0.119857\n",
      "\t partial train loss (single batch): 0.121472\n",
      "\t partial train loss (single batch): 0.120662\n",
      "\t partial train loss (single batch): 0.121290\n",
      "\t partial train loss (single batch): 0.116322\n",
      "\t partial train loss (single batch): 0.115450\n",
      "\t partial train loss (single batch): 0.118762\n",
      "\t partial train loss (single batch): 0.115048\n",
      "\t partial train loss (single batch): 0.111392\n",
      "\t partial train loss (single batch): 0.114384\n",
      "\t partial train loss (single batch): 0.105460\n",
      "\t partial train loss (single batch): 0.106531\n",
      "\t partial train loss (single batch): 0.109358\n",
      "\t partial train loss (single batch): 0.105609\n",
      "\t partial train loss (single batch): 0.107618\n",
      "\t partial train loss (single batch): 0.101135\n",
      "\t partial train loss (single batch): 0.110342\n",
      "\t partial train loss (single batch): 0.102952\n",
      "\t partial train loss (single batch): 0.105267\n",
      "\t partial train loss (single batch): 0.101562\n",
      "\t partial train loss (single batch): 0.102693\n",
      "\t partial train loss (single batch): 0.100809\n",
      "\t partial train loss (single batch): 0.103966\n",
      "\t partial train loss (single batch): 0.100504\n",
      "\t partial train loss (single batch): 0.095149\n",
      "\t partial train loss (single batch): 0.098709\n",
      "\t partial train loss (single batch): 0.096486\n",
      "\t partial train loss (single batch): 0.094727\n",
      "\t partial train loss (single batch): 0.097214\n",
      "\t partial train loss (single batch): 0.097963\n",
      "\t partial train loss (single batch): 0.096527\n",
      "\t partial train loss (single batch): 0.099853\n",
      "\t partial train loss (single batch): 0.097280\n",
      "\t partial train loss (single batch): 0.093410\n",
      "\t partial train loss (single batch): 0.096648\n",
      "\t partial train loss (single batch): 0.096335\n",
      "\t partial train loss (single batch): 0.097385\n",
      "\t partial train loss (single batch): 0.092880\n",
      "\t partial train loss (single batch): 0.100583\n",
      "\t partial train loss (single batch): 0.096174\n",
      "\t partial train loss (single batch): 0.093124\n",
      "\t partial train loss (single batch): 0.094344\n",
      "\t partial train loss (single batch): 0.090699\n",
      "\t partial train loss (single batch): 0.090884\n",
      "\t partial train loss (single batch): 0.094897\n",
      "\t partial train loss (single batch): 0.092760\n",
      "\t partial train loss (single batch): 0.095899\n",
      "\t partial train loss (single batch): 0.095029\n",
      "\t partial train loss (single batch): 0.096542\n",
      "\t partial train loss (single batch): 0.094374\n",
      "\t partial train loss (single batch): 0.096535\n",
      "\t partial train loss (single batch): 0.093239\n",
      "\t partial train loss (single batch): 0.096172\n",
      "\t partial train loss (single batch): 0.093174\n",
      "\t partial train loss (single batch): 0.090257\n",
      "\t partial train loss (single batch): 0.095016\n",
      "\t partial train loss (single batch): 0.099025\n",
      "\t partial train loss (single batch): 0.091187\n",
      "\t partial train loss (single batch): 0.094409\n",
      "\t partial train loss (single batch): 0.091168\n",
      "\t partial train loss (single batch): 0.091512\n",
      "\t partial train loss (single batch): 0.094668\n",
      "\t partial train loss (single batch): 0.094274\n",
      "\t partial train loss (single batch): 0.095282\n",
      "\t partial train loss (single batch): 0.092512\n",
      "\t partial train loss (single batch): 0.090285\n",
      "\t partial train loss (single batch): 0.088967\n",
      "\t partial train loss (single batch): 0.088340\n",
      "\t partial train loss (single batch): 0.092676\n",
      "\t partial train loss (single batch): 0.091806\n",
      "\t partial train loss (single batch): 0.089107\n",
      "\t partial train loss (single batch): 0.092905\n",
      "\t partial train loss (single batch): 0.091782\n",
      "\t partial train loss (single batch): 0.088711\n",
      "\t partial train loss (single batch): 0.089034\n",
      "\t partial train loss (single batch): 0.089817\n",
      "\t partial train loss (single batch): 0.087108\n",
      "\t partial train loss (single batch): 0.088576\n",
      "\t partial train loss (single batch): 0.089655\n",
      "\t partial train loss (single batch): 0.087535\n",
      "\t partial train loss (single batch): 0.090724\n",
      "\t partial train loss (single batch): 0.087876\n",
      "\t partial train loss (single batch): 0.091181\n",
      "\t partial train loss (single batch): 0.091045\n",
      "\t partial train loss (single batch): 0.089740\n",
      "\t partial train loss (single batch): 0.085356\n",
      "\t partial train loss (single batch): 0.087825\n",
      "\t partial train loss (single batch): 0.090768\n",
      "\t partial train loss (single batch): 0.082716\n",
      "\t partial train loss (single batch): 0.082163\n",
      "\t partial train loss (single batch): 0.089289\n",
      "\t partial train loss (single batch): 0.086604\n",
      "\t partial train loss (single batch): 0.086518\n",
      "\t partial train loss (single batch): 0.089795\n",
      "\t partial train loss (single batch): 0.083725\n",
      "\t partial train loss (single batch): 0.088471\n",
      "\t partial train loss (single batch): 0.084914\n",
      "\t partial train loss (single batch): 0.089530\n",
      "\t partial train loss (single batch): 0.089037\n",
      "\t partial train loss (single batch): 0.088596\n",
      "\t partial train loss (single batch): 0.085479\n",
      "\t partial train loss (single batch): 0.085342\n",
      "\t partial train loss (single batch): 0.083658\n",
      "\t partial train loss (single batch): 0.084745\n",
      "\t partial train loss (single batch): 0.085199\n",
      "\t partial train loss (single batch): 0.090444\n",
      "\t partial train loss (single batch): 0.087330\n",
      "\t partial train loss (single batch): 0.086480\n",
      "\t partial train loss (single batch): 0.087656\n",
      "\t partial train loss (single batch): 0.080465\n",
      "\t partial train loss (single batch): 0.089853\n",
      "\t partial train loss (single batch): 0.086824\n",
      "\t partial train loss (single batch): 0.091533\n",
      "\t partial train loss (single batch): 0.089830\n",
      "\t partial train loss (single batch): 0.088132\n",
      "\t partial train loss (single batch): 0.083674\n",
      "\t partial train loss (single batch): 0.081608\n",
      "\t partial train loss (single batch): 0.089191\n",
      "\t partial train loss (single batch): 0.083254\n",
      "\t partial train loss (single batch): 0.084325\n",
      "\t partial train loss (single batch): 0.083654\n",
      "\t partial train loss (single batch): 0.087988\n",
      "\t partial train loss (single batch): 0.083365\n",
      "\t partial train loss (single batch): 0.086391\n",
      "\t partial train loss (single batch): 0.084147\n",
      "\t partial train loss (single batch): 0.088223\n",
      "\t partial train loss (single batch): 0.084766\n",
      "\t partial train loss (single batch): 0.087516\n",
      "\t partial train loss (single batch): 0.084892\n",
      "\t partial train loss (single batch): 0.090113\n",
      "\t partial train loss (single batch): 0.082525\n",
      "\t partial train loss (single batch): 0.086444\n",
      "\t partial train loss (single batch): 0.086572\n",
      "\t partial train loss (single batch): 0.081186\n",
      "\t partial train loss (single batch): 0.082486\n",
      "\t partial train loss (single batch): 0.086425\n",
      "\t partial train loss (single batch): 0.086798\n",
      "\t partial train loss (single batch): 0.086804\n",
      "\t partial train loss (single batch): 0.086068\n",
      "\t partial train loss (single batch): 0.084994\n",
      "\t partial train loss (single batch): 0.084070\n",
      "\t partial train loss (single batch): 0.087149\n",
      "\t partial train loss (single batch): 0.085438\n",
      "\t partial train loss (single batch): 0.082771\n",
      "\t partial train loss (single batch): 0.083039\n",
      "\t partial train loss (single batch): 0.083199\n",
      "\t partial train loss (single batch): 0.084841\n",
      "\t partial train loss (single batch): 0.082568\n",
      "\t partial train loss (single batch): 0.085673\n",
      "\t partial train loss (single batch): 0.084836\n",
      "\t partial train loss (single batch): 0.080678\n",
      "\t partial train loss (single batch): 0.081816\n",
      "\t partial train loss (single batch): 0.080482\n",
      "\t partial train loss (single batch): 0.076560\n",
      "\t partial train loss (single batch): 0.082690\n",
      "\t partial train loss (single batch): 0.084892\n",
      "\t partial train loss (single batch): 0.080613\n",
      "\t partial train loss (single batch): 0.080771\n",
      "\t partial train loss (single batch): 0.080689\n",
      "\t partial train loss (single batch): 0.083053\n",
      "\t partial train loss (single batch): 0.079515\n",
      "\t partial train loss (single batch): 0.081554\n",
      "\t partial train loss (single batch): 0.079333\n",
      "\t partial train loss (single batch): 0.080345\n",
      "\t partial train loss (single batch): 0.079220\n",
      "\t partial train loss (single batch): 0.081588\n",
      "\t partial train loss (single batch): 0.078678\n",
      "\t partial train loss (single batch): 0.082115\n",
      "\t partial train loss (single batch): 0.079061\n",
      "\t partial train loss (single batch): 0.079396\n",
      "\t partial train loss (single batch): 0.075176\n",
      "\t partial train loss (single batch): 0.078792\n",
      "\t partial train loss (single batch): 0.081090\n",
      "\t partial train loss (single batch): 0.081426\n",
      "\t partial train loss (single batch): 0.080220\n",
      "\t partial train loss (single batch): 0.079738\n",
      "\t partial train loss (single batch): 0.073772\n",
      "\t partial train loss (single batch): 0.076623\n",
      "\t partial train loss (single batch): 0.075764\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 1/10 - loss: 0.075065\n",
      "\n",
      "\n",
      "EPOCH 2/10\n",
      "\t partial train loss (single batch): 0.074567\n",
      "\t partial train loss (single batch): 0.076128\n",
      "\t partial train loss (single batch): 0.076460\n",
      "\t partial train loss (single batch): 0.074453\n",
      "\t partial train loss (single batch): 0.073706\n",
      "\t partial train loss (single batch): 0.076256\n",
      "\t partial train loss (single batch): 0.076913\n",
      "\t partial train loss (single batch): 0.069596\n",
      "\t partial train loss (single batch): 0.070751\n",
      "\t partial train loss (single batch): 0.070980\n",
      "\t partial train loss (single batch): 0.072205\n",
      "\t partial train loss (single batch): 0.077376\n",
      "\t partial train loss (single batch): 0.074714\n",
      "\t partial train loss (single batch): 0.072388\n",
      "\t partial train loss (single batch): 0.073537\n",
      "\t partial train loss (single batch): 0.067957\n",
      "\t partial train loss (single batch): 0.071725\n",
      "\t partial train loss (single batch): 0.068189\n",
      "\t partial train loss (single batch): 0.070405\n",
      "\t partial train loss (single batch): 0.068141\n",
      "\t partial train loss (single batch): 0.072333\n",
      "\t partial train loss (single batch): 0.067857\n",
      "\t partial train loss (single batch): 0.068587\n",
      "\t partial train loss (single batch): 0.072365\n",
      "\t partial train loss (single batch): 0.068733\n",
      "\t partial train loss (single batch): 0.067897\n",
      "\t partial train loss (single batch): 0.071593\n",
      "\t partial train loss (single batch): 0.066524\n",
      "\t partial train loss (single batch): 0.068178\n",
      "\t partial train loss (single batch): 0.072523\n",
      "\t partial train loss (single batch): 0.066272\n",
      "\t partial train loss (single batch): 0.064022\n",
      "\t partial train loss (single batch): 0.072932\n",
      "\t partial train loss (single batch): 0.068599\n",
      "\t partial train loss (single batch): 0.069470\n",
      "\t partial train loss (single batch): 0.067052\n",
      "\t partial train loss (single batch): 0.062463\n",
      "\t partial train loss (single batch): 0.066617\n",
      "\t partial train loss (single batch): 0.067509\n",
      "\t partial train loss (single batch): 0.066713\n",
      "\t partial train loss (single batch): 0.068469\n",
      "\t partial train loss (single batch): 0.062261\n",
      "\t partial train loss (single batch): 0.062610\n",
      "\t partial train loss (single batch): 0.067433\n",
      "\t partial train loss (single batch): 0.068144\n",
      "\t partial train loss (single batch): 0.065902\n",
      "\t partial train loss (single batch): 0.065431\n",
      "\t partial train loss (single batch): 0.062480\n",
      "\t partial train loss (single batch): 0.065153\n",
      "\t partial train loss (single batch): 0.062822\n",
      "\t partial train loss (single batch): 0.063338\n",
      "\t partial train loss (single batch): 0.064095\n",
      "\t partial train loss (single batch): 0.064820\n",
      "\t partial train loss (single batch): 0.063156\n",
      "\t partial train loss (single batch): 0.063533\n",
      "\t partial train loss (single batch): 0.065610\n",
      "\t partial train loss (single batch): 0.066886\n",
      "\t partial train loss (single batch): 0.062590\n",
      "\t partial train loss (single batch): 0.063904\n",
      "\t partial train loss (single batch): 0.057883\n",
      "\t partial train loss (single batch): 0.065968\n",
      "\t partial train loss (single batch): 0.062007\n",
      "\t partial train loss (single batch): 0.061733\n",
      "\t partial train loss (single batch): 0.061776\n",
      "\t partial train loss (single batch): 0.058956\n",
      "\t partial train loss (single batch): 0.058897\n",
      "\t partial train loss (single batch): 0.061135\n",
      "\t partial train loss (single batch): 0.058796\n",
      "\t partial train loss (single batch): 0.060049\n",
      "\t partial train loss (single batch): 0.058836\n",
      "\t partial train loss (single batch): 0.064117\n",
      "\t partial train loss (single batch): 0.060395\n",
      "\t partial train loss (single batch): 0.061022\n",
      "\t partial train loss (single batch): 0.057717\n",
      "\t partial train loss (single batch): 0.059951\n",
      "\t partial train loss (single batch): 0.060411\n",
      "\t partial train loss (single batch): 0.057934\n",
      "\t partial train loss (single batch): 0.057025\n",
      "\t partial train loss (single batch): 0.067570\n",
      "\t partial train loss (single batch): 0.059684\n",
      "\t partial train loss (single batch): 0.060947\n",
      "\t partial train loss (single batch): 0.058060\n",
      "\t partial train loss (single batch): 0.059491\n",
      "\t partial train loss (single batch): 0.059912\n",
      "\t partial train loss (single batch): 0.057020\n",
      "\t partial train loss (single batch): 0.058706\n",
      "\t partial train loss (single batch): 0.056229\n",
      "\t partial train loss (single batch): 0.054790\n",
      "\t partial train loss (single batch): 0.054446\n",
      "\t partial train loss (single batch): 0.056369\n",
      "\t partial train loss (single batch): 0.057679\n",
      "\t partial train loss (single batch): 0.060417\n",
      "\t partial train loss (single batch): 0.059764\n",
      "\t partial train loss (single batch): 0.056418\n",
      "\t partial train loss (single batch): 0.054576\n",
      "\t partial train loss (single batch): 0.057928\n",
      "\t partial train loss (single batch): 0.056474\n",
      "\t partial train loss (single batch): 0.055763\n",
      "\t partial train loss (single batch): 0.058019\n",
      "\t partial train loss (single batch): 0.055064\n",
      "\t partial train loss (single batch): 0.058831\n",
      "\t partial train loss (single batch): 0.058687\n",
      "\t partial train loss (single batch): 0.059054\n",
      "\t partial train loss (single batch): 0.055316\n",
      "\t partial train loss (single batch): 0.057746\n",
      "\t partial train loss (single batch): 0.057029\n",
      "\t partial train loss (single batch): 0.056278\n",
      "\t partial train loss (single batch): 0.054376\n",
      "\t partial train loss (single batch): 0.054538\n",
      "\t partial train loss (single batch): 0.056003\n",
      "\t partial train loss (single batch): 0.053171\n",
      "\t partial train loss (single batch): 0.055045\n",
      "\t partial train loss (single batch): 0.056466\n",
      "\t partial train loss (single batch): 0.055593\n",
      "\t partial train loss (single batch): 0.050759\n",
      "\t partial train loss (single batch): 0.050847\n",
      "\t partial train loss (single batch): 0.051803\n",
      "\t partial train loss (single batch): 0.050097\n",
      "\t partial train loss (single batch): 0.051911\n",
      "\t partial train loss (single batch): 0.050276\n",
      "\t partial train loss (single batch): 0.054313\n",
      "\t partial train loss (single batch): 0.056428\n",
      "\t partial train loss (single batch): 0.051498\n",
      "\t partial train loss (single batch): 0.052797\n",
      "\t partial train loss (single batch): 0.053089\n",
      "\t partial train loss (single batch): 0.054719\n",
      "\t partial train loss (single batch): 0.049756\n",
      "\t partial train loss (single batch): 0.054269\n",
      "\t partial train loss (single batch): 0.049349\n",
      "\t partial train loss (single batch): 0.051032\n",
      "\t partial train loss (single batch): 0.053105\n",
      "\t partial train loss (single batch): 0.053578\n",
      "\t partial train loss (single batch): 0.050409\n",
      "\t partial train loss (single batch): 0.049487\n",
      "\t partial train loss (single batch): 0.054050\n",
      "\t partial train loss (single batch): 0.051998\n",
      "\t partial train loss (single batch): 0.051148\n",
      "\t partial train loss (single batch): 0.049530\n",
      "\t partial train loss (single batch): 0.050604\n",
      "\t partial train loss (single batch): 0.048923\n",
      "\t partial train loss (single batch): 0.052484\n",
      "\t partial train loss (single batch): 0.048042\n",
      "\t partial train loss (single batch): 0.051811\n",
      "\t partial train loss (single batch): 0.047461\n",
      "\t partial train loss (single batch): 0.051797\n",
      "\t partial train loss (single batch): 0.049384\n",
      "\t partial train loss (single batch): 0.049780\n",
      "\t partial train loss (single batch): 0.051183\n",
      "\t partial train loss (single batch): 0.049280\n",
      "\t partial train loss (single batch): 0.051455\n",
      "\t partial train loss (single batch): 0.049217\n",
      "\t partial train loss (single batch): 0.049413\n",
      "\t partial train loss (single batch): 0.049276\n",
      "\t partial train loss (single batch): 0.049946\n",
      "\t partial train loss (single batch): 0.044248\n",
      "\t partial train loss (single batch): 0.047178\n",
      "\t partial train loss (single batch): 0.048542\n",
      "\t partial train loss (single batch): 0.045576\n",
      "\t partial train loss (single batch): 0.046536\n",
      "\t partial train loss (single batch): 0.050466\n",
      "\t partial train loss (single batch): 0.048053\n",
      "\t partial train loss (single batch): 0.048107\n",
      "\t partial train loss (single batch): 0.047159\n",
      "\t partial train loss (single batch): 0.048818\n",
      "\t partial train loss (single batch): 0.048405\n",
      "\t partial train loss (single batch): 0.048904\n",
      "\t partial train loss (single batch): 0.044899\n",
      "\t partial train loss (single batch): 0.046625\n",
      "\t partial train loss (single batch): 0.045413\n",
      "\t partial train loss (single batch): 0.049584\n",
      "\t partial train loss (single batch): 0.045827\n",
      "\t partial train loss (single batch): 0.044815\n",
      "\t partial train loss (single batch): 0.045411\n",
      "\t partial train loss (single batch): 0.047288\n",
      "\t partial train loss (single batch): 0.049146\n",
      "\t partial train loss (single batch): 0.045657\n",
      "\t partial train loss (single batch): 0.050288\n",
      "\t partial train loss (single batch): 0.047469\n",
      "\t partial train loss (single batch): 0.045282\n",
      "\t partial train loss (single batch): 0.046998\n",
      "\t partial train loss (single batch): 0.048652\n",
      "\t partial train loss (single batch): 0.046816\n",
      "\t partial train loss (single batch): 0.043111\n",
      "\t partial train loss (single batch): 0.046272\n",
      "\t partial train loss (single batch): 0.046160\n",
      "\t partial train loss (single batch): 0.045382\n",
      "\t partial train loss (single batch): 0.047688\n",
      "\t partial train loss (single batch): 0.045829\n",
      "\t partial train loss (single batch): 0.044116\n",
      "\t partial train loss (single batch): 0.045830\n",
      "\t partial train loss (single batch): 0.043236\n",
      "\t partial train loss (single batch): 0.044408\n",
      "\t partial train loss (single batch): 0.046209\n",
      "\t partial train loss (single batch): 0.047242\n",
      "\t partial train loss (single batch): 0.045093\n",
      "\t partial train loss (single batch): 0.044479\n",
      "\t partial train loss (single batch): 0.043458\n",
      "\t partial train loss (single batch): 0.045942\n",
      "\t partial train loss (single batch): 0.043267\n",
      "\t partial train loss (single batch): 0.044864\n",
      "\t partial train loss (single batch): 0.045703\n",
      "\t partial train loss (single batch): 0.041934\n",
      "\t partial train loss (single batch): 0.043378\n",
      "\t partial train loss (single batch): 0.046554\n",
      "\t partial train loss (single batch): 0.042989\n",
      "\t partial train loss (single batch): 0.046783\n",
      "\t partial train loss (single batch): 0.041520\n",
      "\t partial train loss (single batch): 0.043863\n",
      "\t partial train loss (single batch): 0.045424\n",
      "\t partial train loss (single batch): 0.046121\n",
      "\t partial train loss (single batch): 0.047277\n",
      "\t partial train loss (single batch): 0.042027\n",
      "\t partial train loss (single batch): 0.046558\n",
      "\t partial train loss (single batch): 0.047445\n",
      "\t partial train loss (single batch): 0.043344\n",
      "\t partial train loss (single batch): 0.042273\n",
      "\t partial train loss (single batch): 0.044108\n",
      "\t partial train loss (single batch): 0.046213\n",
      "\t partial train loss (single batch): 0.043160\n",
      "\t partial train loss (single batch): 0.041137\n",
      "\t partial train loss (single batch): 0.045893\n",
      "\t partial train loss (single batch): 0.043269\n",
      "\t partial train loss (single batch): 0.043598\n",
      "\t partial train loss (single batch): 0.044405\n",
      "\t partial train loss (single batch): 0.044660\n",
      "\t partial train loss (single batch): 0.042078\n",
      "\t partial train loss (single batch): 0.043353\n",
      "\t partial train loss (single batch): 0.043500\n",
      "\t partial train loss (single batch): 0.045384\n",
      "\t partial train loss (single batch): 0.045283\n",
      "\t partial train loss (single batch): 0.044054\n",
      "\t partial train loss (single batch): 0.042226\n",
      "\t partial train loss (single batch): 0.045233\n",
      "\t partial train loss (single batch): 0.044509\n",
      "\t partial train loss (single batch): 0.040682\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 2/10 - loss: 0.043461\n",
      "\n",
      "\n",
      "EPOCH 3/10\n",
      "\t partial train loss (single batch): 0.046230\n",
      "\t partial train loss (single batch): 0.043848\n",
      "\t partial train loss (single batch): 0.042858\n",
      "\t partial train loss (single batch): 0.045926\n",
      "\t partial train loss (single batch): 0.045714\n",
      "\t partial train loss (single batch): 0.041267\n",
      "\t partial train loss (single batch): 0.043020\n",
      "\t partial train loss (single batch): 0.041988\n",
      "\t partial train loss (single batch): 0.044515\n",
      "\t partial train loss (single batch): 0.041994\n",
      "\t partial train loss (single batch): 0.046004\n",
      "\t partial train loss (single batch): 0.043868\n",
      "\t partial train loss (single batch): 0.045967\n",
      "\t partial train loss (single batch): 0.041962\n",
      "\t partial train loss (single batch): 0.041877\n",
      "\t partial train loss (single batch): 0.042844\n",
      "\t partial train loss (single batch): 0.039102\n",
      "\t partial train loss (single batch): 0.041924\n",
      "\t partial train loss (single batch): 0.041449\n",
      "\t partial train loss (single batch): 0.042514\n",
      "\t partial train loss (single batch): 0.044587\n",
      "\t partial train loss (single batch): 0.042560\n",
      "\t partial train loss (single batch): 0.043156\n",
      "\t partial train loss (single batch): 0.040332\n",
      "\t partial train loss (single batch): 0.042027\n",
      "\t partial train loss (single batch): 0.041472\n",
      "\t partial train loss (single batch): 0.041133\n",
      "\t partial train loss (single batch): 0.040931\n",
      "\t partial train loss (single batch): 0.039667\n",
      "\t partial train loss (single batch): 0.042089\n",
      "\t partial train loss (single batch): 0.041895\n",
      "\t partial train loss (single batch): 0.042033\n",
      "\t partial train loss (single batch): 0.043664\n",
      "\t partial train loss (single batch): 0.043980\n",
      "\t partial train loss (single batch): 0.040581\n",
      "\t partial train loss (single batch): 0.041005\n",
      "\t partial train loss (single batch): 0.040682\n",
      "\t partial train loss (single batch): 0.040304\n",
      "\t partial train loss (single batch): 0.041518\n",
      "\t partial train loss (single batch): 0.044670\n",
      "\t partial train loss (single batch): 0.043754\n",
      "\t partial train loss (single batch): 0.043010\n",
      "\t partial train loss (single batch): 0.040168\n",
      "\t partial train loss (single batch): 0.040909\n",
      "\t partial train loss (single batch): 0.039154\n",
      "\t partial train loss (single batch): 0.039375\n",
      "\t partial train loss (single batch): 0.042361\n",
      "\t partial train loss (single batch): 0.041896\n",
      "\t partial train loss (single batch): 0.041249\n",
      "\t partial train loss (single batch): 0.040663\n",
      "\t partial train loss (single batch): 0.039579\n",
      "\t partial train loss (single batch): 0.042777\n",
      "\t partial train loss (single batch): 0.040295\n",
      "\t partial train loss (single batch): 0.040069\n",
      "\t partial train loss (single batch): 0.044473\n",
      "\t partial train loss (single batch): 0.039476\n",
      "\t partial train loss (single batch): 0.040325\n",
      "\t partial train loss (single batch): 0.038849\n",
      "\t partial train loss (single batch): 0.039836\n",
      "\t partial train loss (single batch): 0.037368\n",
      "\t partial train loss (single batch): 0.040438\n",
      "\t partial train loss (single batch): 0.040861\n",
      "\t partial train loss (single batch): 0.040228\n",
      "\t partial train loss (single batch): 0.040552\n",
      "\t partial train loss (single batch): 0.037635\n",
      "\t partial train loss (single batch): 0.039084\n",
      "\t partial train loss (single batch): 0.041587\n",
      "\t partial train loss (single batch): 0.041415\n",
      "\t partial train loss (single batch): 0.042121\n",
      "\t partial train loss (single batch): 0.041386\n",
      "\t partial train loss (single batch): 0.041771\n",
      "\t partial train loss (single batch): 0.040258\n",
      "\t partial train loss (single batch): 0.040009\n",
      "\t partial train loss (single batch): 0.040300\n",
      "\t partial train loss (single batch): 0.041147\n",
      "\t partial train loss (single batch): 0.040387\n",
      "\t partial train loss (single batch): 0.038530\n",
      "\t partial train loss (single batch): 0.039815\n",
      "\t partial train loss (single batch): 0.039933\n",
      "\t partial train loss (single batch): 0.041454\n",
      "\t partial train loss (single batch): 0.040904\n",
      "\t partial train loss (single batch): 0.039940\n",
      "\t partial train loss (single batch): 0.040201\n",
      "\t partial train loss (single batch): 0.042754\n",
      "\t partial train loss (single batch): 0.043533\n",
      "\t partial train loss (single batch): 0.038371\n",
      "\t partial train loss (single batch): 0.039186\n",
      "\t partial train loss (single batch): 0.039700\n",
      "\t partial train loss (single batch): 0.040744\n",
      "\t partial train loss (single batch): 0.040345\n",
      "\t partial train loss (single batch): 0.039886\n",
      "\t partial train loss (single batch): 0.039721\n",
      "\t partial train loss (single batch): 0.040864\n",
      "\t partial train loss (single batch): 0.039393\n",
      "\t partial train loss (single batch): 0.039479\n",
      "\t partial train loss (single batch): 0.040018\n",
      "\t partial train loss (single batch): 0.040039\n",
      "\t partial train loss (single batch): 0.041341\n",
      "\t partial train loss (single batch): 0.042442\n",
      "\t partial train loss (single batch): 0.039141\n",
      "\t partial train loss (single batch): 0.038853\n",
      "\t partial train loss (single batch): 0.039320\n",
      "\t partial train loss (single batch): 0.037988\n",
      "\t partial train loss (single batch): 0.038293\n",
      "\t partial train loss (single batch): 0.040483\n",
      "\t partial train loss (single batch): 0.040170\n",
      "\t partial train loss (single batch): 0.040140\n",
      "\t partial train loss (single batch): 0.038266\n",
      "\t partial train loss (single batch): 0.041023\n",
      "\t partial train loss (single batch): 0.041144\n",
      "\t partial train loss (single batch): 0.041002\n",
      "\t partial train loss (single batch): 0.039562\n",
      "\t partial train loss (single batch): 0.039969\n",
      "\t partial train loss (single batch): 0.040087\n",
      "\t partial train loss (single batch): 0.039206\n",
      "\t partial train loss (single batch): 0.041952\n",
      "\t partial train loss (single batch): 0.041008\n",
      "\t partial train loss (single batch): 0.037980\n",
      "\t partial train loss (single batch): 0.037401\n",
      "\t partial train loss (single batch): 0.037636\n",
      "\t partial train loss (single batch): 0.038521\n",
      "\t partial train loss (single batch): 0.039141\n",
      "\t partial train loss (single batch): 0.040208\n",
      "\t partial train loss (single batch): 0.042251\n",
      "\t partial train loss (single batch): 0.039854\n",
      "\t partial train loss (single batch): 0.037321\n",
      "\t partial train loss (single batch): 0.039017\n",
      "\t partial train loss (single batch): 0.037559\n",
      "\t partial train loss (single batch): 0.039872\n",
      "\t partial train loss (single batch): 0.038578\n",
      "\t partial train loss (single batch): 0.040776\n",
      "\t partial train loss (single batch): 0.039987\n",
      "\t partial train loss (single batch): 0.038745\n",
      "\t partial train loss (single batch): 0.038933\n",
      "\t partial train loss (single batch): 0.040609\n",
      "\t partial train loss (single batch): 0.037998\n",
      "\t partial train loss (single batch): 0.038105\n",
      "\t partial train loss (single batch): 0.037671\n",
      "\t partial train loss (single batch): 0.039131\n",
      "\t partial train loss (single batch): 0.039645\n",
      "\t partial train loss (single batch): 0.039193\n",
      "\t partial train loss (single batch): 0.035773\n",
      "\t partial train loss (single batch): 0.038888\n",
      "\t partial train loss (single batch): 0.040601\n",
      "\t partial train loss (single batch): 0.040298\n",
      "\t partial train loss (single batch): 0.037812\n",
      "\t partial train loss (single batch): 0.039956\n",
      "\t partial train loss (single batch): 0.040738\n",
      "\t partial train loss (single batch): 0.037019\n",
      "\t partial train loss (single batch): 0.039626\n",
      "\t partial train loss (single batch): 0.042060\n",
      "\t partial train loss (single batch): 0.040154\n",
      "\t partial train loss (single batch): 0.038195\n",
      "\t partial train loss (single batch): 0.040113\n",
      "\t partial train loss (single batch): 0.039883\n",
      "\t partial train loss (single batch): 0.039890\n",
      "\t partial train loss (single batch): 0.038233\n",
      "\t partial train loss (single batch): 0.038388\n",
      "\t partial train loss (single batch): 0.040026\n",
      "\t partial train loss (single batch): 0.039261\n",
      "\t partial train loss (single batch): 0.039131\n",
      "\t partial train loss (single batch): 0.039178\n",
      "\t partial train loss (single batch): 0.039594\n",
      "\t partial train loss (single batch): 0.039747\n",
      "\t partial train loss (single batch): 0.040250\n",
      "\t partial train loss (single batch): 0.040201\n",
      "\t partial train loss (single batch): 0.040761\n",
      "\t partial train loss (single batch): 0.038054\n",
      "\t partial train loss (single batch): 0.041469\n",
      "\t partial train loss (single batch): 0.039979\n",
      "\t partial train loss (single batch): 0.039544\n",
      "\t partial train loss (single batch): 0.042035\n",
      "\t partial train loss (single batch): 0.040319\n",
      "\t partial train loss (single batch): 0.038319\n",
      "\t partial train loss (single batch): 0.040846\n",
      "\t partial train loss (single batch): 0.039847\n",
      "\t partial train loss (single batch): 0.040623\n",
      "\t partial train loss (single batch): 0.040393\n",
      "\t partial train loss (single batch): 0.042670\n",
      "\t partial train loss (single batch): 0.040741\n",
      "\t partial train loss (single batch): 0.040676\n",
      "\t partial train loss (single batch): 0.038001\n",
      "\t partial train loss (single batch): 0.040154\n",
      "\t partial train loss (single batch): 0.037241\n",
      "\t partial train loss (single batch): 0.039708\n",
      "\t partial train loss (single batch): 0.037654\n",
      "\t partial train loss (single batch): 0.038062\n",
      "\t partial train loss (single batch): 0.036182\n",
      "\t partial train loss (single batch): 0.038879\n",
      "\t partial train loss (single batch): 0.038249\n",
      "\t partial train loss (single batch): 0.042089\n",
      "\t partial train loss (single batch): 0.038364\n",
      "\t partial train loss (single batch): 0.040326\n",
      "\t partial train loss (single batch): 0.038797\n",
      "\t partial train loss (single batch): 0.040612\n",
      "\t partial train loss (single batch): 0.040993\n",
      "\t partial train loss (single batch): 0.036982\n",
      "\t partial train loss (single batch): 0.041156\n",
      "\t partial train loss (single batch): 0.037944\n",
      "\t partial train loss (single batch): 0.040609\n",
      "\t partial train loss (single batch): 0.041306\n",
      "\t partial train loss (single batch): 0.039582\n",
      "\t partial train loss (single batch): 0.039107\n",
      "\t partial train loss (single batch): 0.039239\n",
      "\t partial train loss (single batch): 0.040177\n",
      "\t partial train loss (single batch): 0.037797\n",
      "\t partial train loss (single batch): 0.039125\n",
      "\t partial train loss (single batch): 0.039364\n",
      "\t partial train loss (single batch): 0.039124\n",
      "\t partial train loss (single batch): 0.038208\n",
      "\t partial train loss (single batch): 0.039454\n",
      "\t partial train loss (single batch): 0.038629\n",
      "\t partial train loss (single batch): 0.036981\n",
      "\t partial train loss (single batch): 0.036122\n",
      "\t partial train loss (single batch): 0.037741\n",
      "\t partial train loss (single batch): 0.040932\n",
      "\t partial train loss (single batch): 0.037955\n",
      "\t partial train loss (single batch): 0.039305\n",
      "\t partial train loss (single batch): 0.037913\n",
      "\t partial train loss (single batch): 0.042318\n",
      "\t partial train loss (single batch): 0.038180\n",
      "\t partial train loss (single batch): 0.038721\n",
      "\t partial train loss (single batch): 0.038700\n",
      "\t partial train loss (single batch): 0.038221\n",
      "\t partial train loss (single batch): 0.039893\n",
      "\t partial train loss (single batch): 0.038531\n",
      "\t partial train loss (single batch): 0.036600\n",
      "\t partial train loss (single batch): 0.039837\n",
      "\t partial train loss (single batch): 0.037126\n",
      "\t partial train loss (single batch): 0.038630\n",
      "\t partial train loss (single batch): 0.039052\n",
      "\t partial train loss (single batch): 0.037766\n",
      "\t partial train loss (single batch): 0.035169\n",
      "\t partial train loss (single batch): 0.039233\n",
      "\t partial train loss (single batch): 0.036104\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 3/10 - loss: 0.038472\n",
      "\n",
      "\n",
      "EPOCH 4/10\n",
      "\t partial train loss (single batch): 0.037019\n",
      "\t partial train loss (single batch): 0.039960\n",
      "\t partial train loss (single batch): 0.040703\n",
      "\t partial train loss (single batch): 0.040036\n",
      "\t partial train loss (single batch): 0.038640\n",
      "\t partial train loss (single batch): 0.036609\n",
      "\t partial train loss (single batch): 0.037854\n",
      "\t partial train loss (single batch): 0.036979\n",
      "\t partial train loss (single batch): 0.037600\n",
      "\t partial train loss (single batch): 0.039107\n",
      "\t partial train loss (single batch): 0.038365\n",
      "\t partial train loss (single batch): 0.039627\n",
      "\t partial train loss (single batch): 0.038100\n",
      "\t partial train loss (single batch): 0.039050\n",
      "\t partial train loss (single batch): 0.037757\n",
      "\t partial train loss (single batch): 0.039496\n",
      "\t partial train loss (single batch): 0.038658\n",
      "\t partial train loss (single batch): 0.038681\n",
      "\t partial train loss (single batch): 0.038738\n",
      "\t partial train loss (single batch): 0.036345\n",
      "\t partial train loss (single batch): 0.038647\n",
      "\t partial train loss (single batch): 0.039003\n",
      "\t partial train loss (single batch): 0.037940\n",
      "\t partial train loss (single batch): 0.039786\n",
      "\t partial train loss (single batch): 0.038926\n",
      "\t partial train loss (single batch): 0.037331\n",
      "\t partial train loss (single batch): 0.037011\n",
      "\t partial train loss (single batch): 0.038853\n",
      "\t partial train loss (single batch): 0.039337\n",
      "\t partial train loss (single batch): 0.037544\n",
      "\t partial train loss (single batch): 0.038686\n",
      "\t partial train loss (single batch): 0.036697\n",
      "\t partial train loss (single batch): 0.037032\n",
      "\t partial train loss (single batch): 0.038163\n",
      "\t partial train loss (single batch): 0.038446\n",
      "\t partial train loss (single batch): 0.037509\n",
      "\t partial train loss (single batch): 0.036098\n",
      "\t partial train loss (single batch): 0.036803\n",
      "\t partial train loss (single batch): 0.038079\n",
      "\t partial train loss (single batch): 0.037314\n",
      "\t partial train loss (single batch): 0.037971\n",
      "\t partial train loss (single batch): 0.038795\n",
      "\t partial train loss (single batch): 0.036581\n",
      "\t partial train loss (single batch): 0.040803\n",
      "\t partial train loss (single batch): 0.039946\n",
      "\t partial train loss (single batch): 0.039621\n",
      "\t partial train loss (single batch): 0.040193\n",
      "\t partial train loss (single batch): 0.036703\n",
      "\t partial train loss (single batch): 0.037889\n",
      "\t partial train loss (single batch): 0.038708\n",
      "\t partial train loss (single batch): 0.041670\n",
      "\t partial train loss (single batch): 0.035707\n",
      "\t partial train loss (single batch): 0.036076\n",
      "\t partial train loss (single batch): 0.040322\n",
      "\t partial train loss (single batch): 0.037643\n",
      "\t partial train loss (single batch): 0.036511\n",
      "\t partial train loss (single batch): 0.038841\n",
      "\t partial train loss (single batch): 0.040590\n",
      "\t partial train loss (single batch): 0.039801\n",
      "\t partial train loss (single batch): 0.037750\n",
      "\t partial train loss (single batch): 0.038724\n",
      "\t partial train loss (single batch): 0.037770\n",
      "\t partial train loss (single batch): 0.038825\n",
      "\t partial train loss (single batch): 0.035050\n",
      "\t partial train loss (single batch): 0.037009\n",
      "\t partial train loss (single batch): 0.038212\n",
      "\t partial train loss (single batch): 0.036904\n",
      "\t partial train loss (single batch): 0.037618\n",
      "\t partial train loss (single batch): 0.037492\n",
      "\t partial train loss (single batch): 0.039918\n",
      "\t partial train loss (single batch): 0.036591\n",
      "\t partial train loss (single batch): 0.037847\n",
      "\t partial train loss (single batch): 0.038601\n",
      "\t partial train loss (single batch): 0.037765\n",
      "\t partial train loss (single batch): 0.036121\n",
      "\t partial train loss (single batch): 0.037939\n",
      "\t partial train loss (single batch): 0.038360\n",
      "\t partial train loss (single batch): 0.038767\n",
      "\t partial train loss (single batch): 0.036225\n",
      "\t partial train loss (single batch): 0.039980\n",
      "\t partial train loss (single batch): 0.037683\n",
      "\t partial train loss (single batch): 0.037674\n",
      "\t partial train loss (single batch): 0.039505\n",
      "\t partial train loss (single batch): 0.041356\n",
      "\t partial train loss (single batch): 0.039138\n",
      "\t partial train loss (single batch): 0.036491\n",
      "\t partial train loss (single batch): 0.038992\n",
      "\t partial train loss (single batch): 0.036190\n",
      "\t partial train loss (single batch): 0.037260\n",
      "\t partial train loss (single batch): 0.038906\n",
      "\t partial train loss (single batch): 0.039229\n",
      "\t partial train loss (single batch): 0.034926\n",
      "\t partial train loss (single batch): 0.038885\n",
      "\t partial train loss (single batch): 0.038654\n",
      "\t partial train loss (single batch): 0.040660\n",
      "\t partial train loss (single batch): 0.036535\n",
      "\t partial train loss (single batch): 0.038246\n",
      "\t partial train loss (single batch): 0.038704\n",
      "\t partial train loss (single batch): 0.036536\n",
      "\t partial train loss (single batch): 0.037438\n",
      "\t partial train loss (single batch): 0.038771\n",
      "\t partial train loss (single batch): 0.038090\n",
      "\t partial train loss (single batch): 0.040495\n",
      "\t partial train loss (single batch): 0.035892\n",
      "\t partial train loss (single batch): 0.036477\n",
      "\t partial train loss (single batch): 0.038864\n",
      "\t partial train loss (single batch): 0.040193\n",
      "\t partial train loss (single batch): 0.039572\n",
      "\t partial train loss (single batch): 0.035941\n",
      "\t partial train loss (single batch): 0.034827\n",
      "\t partial train loss (single batch): 0.037610\n",
      "\t partial train loss (single batch): 0.035594\n",
      "\t partial train loss (single batch): 0.037471\n",
      "\t partial train loss (single batch): 0.039185\n",
      "\t partial train loss (single batch): 0.036315\n",
      "\t partial train loss (single batch): 0.038897\n",
      "\t partial train loss (single batch): 0.039948\n",
      "\t partial train loss (single batch): 0.034584\n",
      "\t partial train loss (single batch): 0.041102\n",
      "\t partial train loss (single batch): 0.037989\n",
      "\t partial train loss (single batch): 0.035176\n",
      "\t partial train loss (single batch): 0.037674\n",
      "\t partial train loss (single batch): 0.036143\n",
      "\t partial train loss (single batch): 0.033049\n",
      "\t partial train loss (single batch): 0.035493\n",
      "\t partial train loss (single batch): 0.037706\n",
      "\t partial train loss (single batch): 0.038261\n",
      "\t partial train loss (single batch): 0.037606\n",
      "\t partial train loss (single batch): 0.039052\n",
      "\t partial train loss (single batch): 0.038347\n",
      "\t partial train loss (single batch): 0.036156\n",
      "\t partial train loss (single batch): 0.037391\n",
      "\t partial train loss (single batch): 0.041517\n",
      "\t partial train loss (single batch): 0.039325\n",
      "\t partial train loss (single batch): 0.037795\n",
      "\t partial train loss (single batch): 0.036944\n",
      "\t partial train loss (single batch): 0.037649\n",
      "\t partial train loss (single batch): 0.037030\n",
      "\t partial train loss (single batch): 0.037339\n",
      "\t partial train loss (single batch): 0.037404\n",
      "\t partial train loss (single batch): 0.038777\n",
      "\t partial train loss (single batch): 0.036175\n",
      "\t partial train loss (single batch): 0.036088\n",
      "\t partial train loss (single batch): 0.039510\n",
      "\t partial train loss (single batch): 0.038763\n",
      "\t partial train loss (single batch): 0.035522\n",
      "\t partial train loss (single batch): 0.038175\n",
      "\t partial train loss (single batch): 0.036026\n",
      "\t partial train loss (single batch): 0.036940\n",
      "\t partial train loss (single batch): 0.035810\n",
      "\t partial train loss (single batch): 0.039558\n",
      "\t partial train loss (single batch): 0.037772\n",
      "\t partial train loss (single batch): 0.038573\n",
      "\t partial train loss (single batch): 0.038924\n",
      "\t partial train loss (single batch): 0.038174\n",
      "\t partial train loss (single batch): 0.038538\n",
      "\t partial train loss (single batch): 0.037712\n",
      "\t partial train loss (single batch): 0.039636\n",
      "\t partial train loss (single batch): 0.035985\n",
      "\t partial train loss (single batch): 0.038442\n",
      "\t partial train loss (single batch): 0.041421\n",
      "\t partial train loss (single batch): 0.038883\n",
      "\t partial train loss (single batch): 0.035294\n",
      "\t partial train loss (single batch): 0.040308\n",
      "\t partial train loss (single batch): 0.036690\n",
      "\t partial train loss (single batch): 0.035866\n",
      "\t partial train loss (single batch): 0.036675\n",
      "\t partial train loss (single batch): 0.037132\n",
      "\t partial train loss (single batch): 0.038545\n",
      "\t partial train loss (single batch): 0.035965\n",
      "\t partial train loss (single batch): 0.037188\n",
      "\t partial train loss (single batch): 0.035442\n",
      "\t partial train loss (single batch): 0.038403\n",
      "\t partial train loss (single batch): 0.039578\n",
      "\t partial train loss (single batch): 0.038275\n",
      "\t partial train loss (single batch): 0.036317\n",
      "\t partial train loss (single batch): 0.038105\n",
      "\t partial train loss (single batch): 0.035756\n",
      "\t partial train loss (single batch): 0.037174\n",
      "\t partial train loss (single batch): 0.037382\n",
      "\t partial train loss (single batch): 0.038198\n",
      "\t partial train loss (single batch): 0.037060\n",
      "\t partial train loss (single batch): 0.039045\n",
      "\t partial train loss (single batch): 0.037711\n",
      "\t partial train loss (single batch): 0.039042\n",
      "\t partial train loss (single batch): 0.036885\n",
      "\t partial train loss (single batch): 0.037245\n",
      "\t partial train loss (single batch): 0.038005\n",
      "\t partial train loss (single batch): 0.039497\n",
      "\t partial train loss (single batch): 0.037132\n",
      "\t partial train loss (single batch): 0.034623\n",
      "\t partial train loss (single batch): 0.036997\n",
      "\t partial train loss (single batch): 0.035496\n",
      "\t partial train loss (single batch): 0.035998\n",
      "\t partial train loss (single batch): 0.038475\n",
      "\t partial train loss (single batch): 0.036497\n",
      "\t partial train loss (single batch): 0.038000\n",
      "\t partial train loss (single batch): 0.037793\n",
      "\t partial train loss (single batch): 0.034836\n",
      "\t partial train loss (single batch): 0.036313\n",
      "\t partial train loss (single batch): 0.036198\n",
      "\t partial train loss (single batch): 0.034736\n",
      "\t partial train loss (single batch): 0.034236\n",
      "\t partial train loss (single batch): 0.034332\n",
      "\t partial train loss (single batch): 0.038234\n",
      "\t partial train loss (single batch): 0.036271\n",
      "\t partial train loss (single batch): 0.039404\n",
      "\t partial train loss (single batch): 0.038149\n",
      "\t partial train loss (single batch): 0.034513\n",
      "\t partial train loss (single batch): 0.035970\n",
      "\t partial train loss (single batch): 0.036400\n",
      "\t partial train loss (single batch): 0.038191\n",
      "\t partial train loss (single batch): 0.035784\n",
      "\t partial train loss (single batch): 0.040979\n",
      "\t partial train loss (single batch): 0.036366\n",
      "\t partial train loss (single batch): 0.037340\n",
      "\t partial train loss (single batch): 0.037815\n",
      "\t partial train loss (single batch): 0.035324\n",
      "\t partial train loss (single batch): 0.038843\n",
      "\t partial train loss (single batch): 0.035958\n",
      "\t partial train loss (single batch): 0.037298\n",
      "\t partial train loss (single batch): 0.039297\n",
      "\t partial train loss (single batch): 0.040223\n",
      "\t partial train loss (single batch): 0.036190\n",
      "\t partial train loss (single batch): 0.036982\n",
      "\t partial train loss (single batch): 0.037447\n",
      "\t partial train loss (single batch): 0.036923\n",
      "\t partial train loss (single batch): 0.034563\n",
      "\t partial train loss (single batch): 0.041221\n",
      "\t partial train loss (single batch): 0.035955\n",
      "\t partial train loss (single batch): 0.037105\n",
      "\t partial train loss (single batch): 0.036250\n",
      "\t partial train loss (single batch): 0.037615\n",
      "\t partial train loss (single batch): 0.035620\n",
      "\t partial train loss (single batch): 0.040338\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 4/10 - loss: 0.036777\n",
      "\n",
      "\n",
      "EPOCH 5/10\n",
      "\t partial train loss (single batch): 0.036631\n",
      "\t partial train loss (single batch): 0.035263\n",
      "\t partial train loss (single batch): 0.038092\n",
      "\t partial train loss (single batch): 0.036505\n",
      "\t partial train loss (single batch): 0.040387\n",
      "\t partial train loss (single batch): 0.037920\n",
      "\t partial train loss (single batch): 0.036622\n",
      "\t partial train loss (single batch): 0.037309\n",
      "\t partial train loss (single batch): 0.037467\n",
      "\t partial train loss (single batch): 0.033865\n",
      "\t partial train loss (single batch): 0.036606\n",
      "\t partial train loss (single batch): 0.035971\n",
      "\t partial train loss (single batch): 0.037032\n",
      "\t partial train loss (single batch): 0.032949\n",
      "\t partial train loss (single batch): 0.036701\n",
      "\t partial train loss (single batch): 0.035229\n",
      "\t partial train loss (single batch): 0.036399\n",
      "\t partial train loss (single batch): 0.037394\n",
      "\t partial train loss (single batch): 0.036915\n",
      "\t partial train loss (single batch): 0.039904\n",
      "\t partial train loss (single batch): 0.037065\n",
      "\t partial train loss (single batch): 0.041263\n",
      "\t partial train loss (single batch): 0.034671\n",
      "\t partial train loss (single batch): 0.038062\n",
      "\t partial train loss (single batch): 0.037025\n",
      "\t partial train loss (single batch): 0.035670\n",
      "\t partial train loss (single batch): 0.038023\n",
      "\t partial train loss (single batch): 0.035320\n",
      "\t partial train loss (single batch): 0.034340\n",
      "\t partial train loss (single batch): 0.036053\n",
      "\t partial train loss (single batch): 0.035762\n",
      "\t partial train loss (single batch): 0.038881\n",
      "\t partial train loss (single batch): 0.036236\n",
      "\t partial train loss (single batch): 0.035080\n",
      "\t partial train loss (single batch): 0.035531\n",
      "\t partial train loss (single batch): 0.038536\n",
      "\t partial train loss (single batch): 0.037009\n",
      "\t partial train loss (single batch): 0.035136\n",
      "\t partial train loss (single batch): 0.036289\n",
      "\t partial train loss (single batch): 0.036854\n",
      "\t partial train loss (single batch): 0.041010\n",
      "\t partial train loss (single batch): 0.037632\n",
      "\t partial train loss (single batch): 0.036040\n",
      "\t partial train loss (single batch): 0.038132\n",
      "\t partial train loss (single batch): 0.035695\n",
      "\t partial train loss (single batch): 0.035703\n",
      "\t partial train loss (single batch): 0.036300\n",
      "\t partial train loss (single batch): 0.034888\n",
      "\t partial train loss (single batch): 0.035370\n",
      "\t partial train loss (single batch): 0.036968\n",
      "\t partial train loss (single batch): 0.037296\n",
      "\t partial train loss (single batch): 0.038787\n",
      "\t partial train loss (single batch): 0.038093\n",
      "\t partial train loss (single batch): 0.037881\n",
      "\t partial train loss (single batch): 0.037047\n",
      "\t partial train loss (single batch): 0.034245\n",
      "\t partial train loss (single batch): 0.036337\n",
      "\t partial train loss (single batch): 0.037816\n",
      "\t partial train loss (single batch): 0.035110\n",
      "\t partial train loss (single batch): 0.035217\n",
      "\t partial train loss (single batch): 0.036635\n",
      "\t partial train loss (single batch): 0.036983\n",
      "\t partial train loss (single batch): 0.036394\n",
      "\t partial train loss (single batch): 0.038891\n",
      "\t partial train loss (single batch): 0.036541\n",
      "\t partial train loss (single batch): 0.037557\n",
      "\t partial train loss (single batch): 0.037655\n",
      "\t partial train loss (single batch): 0.035769\n",
      "\t partial train loss (single batch): 0.040073\n",
      "\t partial train loss (single batch): 0.036858\n",
      "\t partial train loss (single batch): 0.037155\n",
      "\t partial train loss (single batch): 0.036668\n",
      "\t partial train loss (single batch): 0.037094\n",
      "\t partial train loss (single batch): 0.038011\n",
      "\t partial train loss (single batch): 0.036155\n",
      "\t partial train loss (single batch): 0.039240\n",
      "\t partial train loss (single batch): 0.034391\n",
      "\t partial train loss (single batch): 0.036150\n",
      "\t partial train loss (single batch): 0.035884\n",
      "\t partial train loss (single batch): 0.036654\n",
      "\t partial train loss (single batch): 0.036819\n",
      "\t partial train loss (single batch): 0.037280\n",
      "\t partial train loss (single batch): 0.037416\n",
      "\t partial train loss (single batch): 0.037892\n",
      "\t partial train loss (single batch): 0.038140\n",
      "\t partial train loss (single batch): 0.034788\n",
      "\t partial train loss (single batch): 0.034892\n",
      "\t partial train loss (single batch): 0.037314\n",
      "\t partial train loss (single batch): 0.037027\n",
      "\t partial train loss (single batch): 0.036217\n",
      "\t partial train loss (single batch): 0.035956\n",
      "\t partial train loss (single batch): 0.038137\n",
      "\t partial train loss (single batch): 0.035521\n",
      "\t partial train loss (single batch): 0.037652\n",
      "\t partial train loss (single batch): 0.035310\n",
      "\t partial train loss (single batch): 0.038083\n",
      "\t partial train loss (single batch): 0.034804\n",
      "\t partial train loss (single batch): 0.036564\n",
      "\t partial train loss (single batch): 0.036243\n",
      "\t partial train loss (single batch): 0.036639\n",
      "\t partial train loss (single batch): 0.034990\n",
      "\t partial train loss (single batch): 0.038014\n",
      "\t partial train loss (single batch): 0.037482\n",
      "\t partial train loss (single batch): 0.037206\n",
      "\t partial train loss (single batch): 0.034413\n",
      "\t partial train loss (single batch): 0.037886\n",
      "\t partial train loss (single batch): 0.037981\n",
      "\t partial train loss (single batch): 0.035268\n",
      "\t partial train loss (single batch): 0.036829\n",
      "\t partial train loss (single batch): 0.035807\n",
      "\t partial train loss (single batch): 0.035879\n",
      "\t partial train loss (single batch): 0.037562\n",
      "\t partial train loss (single batch): 0.035155\n",
      "\t partial train loss (single batch): 0.034757\n",
      "\t partial train loss (single batch): 0.035690\n",
      "\t partial train loss (single batch): 0.036545\n",
      "\t partial train loss (single batch): 0.038738\n",
      "\t partial train loss (single batch): 0.036370\n",
      "\t partial train loss (single batch): 0.036736\n",
      "\t partial train loss (single batch): 0.036251\n",
      "\t partial train loss (single batch): 0.036566\n",
      "\t partial train loss (single batch): 0.036997\n",
      "\t partial train loss (single batch): 0.034178\n",
      "\t partial train loss (single batch): 0.035330\n",
      "\t partial train loss (single batch): 0.036572\n",
      "\t partial train loss (single batch): 0.036840\n",
      "\t partial train loss (single batch): 0.035021\n",
      "\t partial train loss (single batch): 0.037901\n",
      "\t partial train loss (single batch): 0.037064\n",
      "\t partial train loss (single batch): 0.037380\n",
      "\t partial train loss (single batch): 0.034573\n",
      "\t partial train loss (single batch): 0.035600\n",
      "\t partial train loss (single batch): 0.037444\n",
      "\t partial train loss (single batch): 0.037248\n",
      "\t partial train loss (single batch): 0.036593\n",
      "\t partial train loss (single batch): 0.037573\n",
      "\t partial train loss (single batch): 0.034605\n",
      "\t partial train loss (single batch): 0.035470\n",
      "\t partial train loss (single batch): 0.036120\n",
      "\t partial train loss (single batch): 0.036738\n",
      "\t partial train loss (single batch): 0.034789\n",
      "\t partial train loss (single batch): 0.035936\n",
      "\t partial train loss (single batch): 0.036634\n",
      "\t partial train loss (single batch): 0.034636\n",
      "\t partial train loss (single batch): 0.036983\n",
      "\t partial train loss (single batch): 0.037450\n",
      "\t partial train loss (single batch): 0.033666\n",
      "\t partial train loss (single batch): 0.039033\n",
      "\t partial train loss (single batch): 0.038005\n",
      "\t partial train loss (single batch): 0.035172\n",
      "\t partial train loss (single batch): 0.035442\n",
      "\t partial train loss (single batch): 0.038598\n",
      "\t partial train loss (single batch): 0.035990\n",
      "\t partial train loss (single batch): 0.034444\n",
      "\t partial train loss (single batch): 0.035975\n",
      "\t partial train loss (single batch): 0.036401\n",
      "\t partial train loss (single batch): 0.034802\n",
      "\t partial train loss (single batch): 0.035217\n",
      "\t partial train loss (single batch): 0.036051\n",
      "\t partial train loss (single batch): 0.035443\n",
      "\t partial train loss (single batch): 0.034924\n",
      "\t partial train loss (single batch): 0.035848\n",
      "\t partial train loss (single batch): 0.035895\n",
      "\t partial train loss (single batch): 0.037613\n",
      "\t partial train loss (single batch): 0.035543\n",
      "\t partial train loss (single batch): 0.035288\n",
      "\t partial train loss (single batch): 0.034767\n",
      "\t partial train loss (single batch): 0.038378\n",
      "\t partial train loss (single batch): 0.036458\n",
      "\t partial train loss (single batch): 0.033700\n",
      "\t partial train loss (single batch): 0.036662\n",
      "\t partial train loss (single batch): 0.036631\n",
      "\t partial train loss (single batch): 0.035898\n",
      "\t partial train loss (single batch): 0.036838\n",
      "\t partial train loss (single batch): 0.035708\n",
      "\t partial train loss (single batch): 0.037721\n",
      "\t partial train loss (single batch): 0.036178\n",
      "\t partial train loss (single batch): 0.037960\n",
      "\t partial train loss (single batch): 0.035801\n",
      "\t partial train loss (single batch): 0.034410\n",
      "\t partial train loss (single batch): 0.035466\n",
      "\t partial train loss (single batch): 0.035746\n",
      "\t partial train loss (single batch): 0.034949\n",
      "\t partial train loss (single batch): 0.035483\n",
      "\t partial train loss (single batch): 0.036549\n",
      "\t partial train loss (single batch): 0.036207\n",
      "\t partial train loss (single batch): 0.037036\n",
      "\t partial train loss (single batch): 0.036049\n",
      "\t partial train loss (single batch): 0.033205\n",
      "\t partial train loss (single batch): 0.037247\n",
      "\t partial train loss (single batch): 0.037215\n",
      "\t partial train loss (single batch): 0.035831\n",
      "\t partial train loss (single batch): 0.034772\n",
      "\t partial train loss (single batch): 0.034628\n",
      "\t partial train loss (single batch): 0.036347\n",
      "\t partial train loss (single batch): 0.038433\n",
      "\t partial train loss (single batch): 0.034579\n",
      "\t partial train loss (single batch): 0.035279\n",
      "\t partial train loss (single batch): 0.034120\n",
      "\t partial train loss (single batch): 0.034265\n",
      "\t partial train loss (single batch): 0.036554\n",
      "\t partial train loss (single batch): 0.035536\n",
      "\t partial train loss (single batch): 0.034097\n",
      "\t partial train loss (single batch): 0.035820\n",
      "\t partial train loss (single batch): 0.034268\n",
      "\t partial train loss (single batch): 0.035178\n",
      "\t partial train loss (single batch): 0.034984\n",
      "\t partial train loss (single batch): 0.035481\n",
      "\t partial train loss (single batch): 0.035471\n",
      "\t partial train loss (single batch): 0.035912\n",
      "\t partial train loss (single batch): 0.038405\n",
      "\t partial train loss (single batch): 0.034623\n",
      "\t partial train loss (single batch): 0.036295\n",
      "\t partial train loss (single batch): 0.036019\n",
      "\t partial train loss (single batch): 0.037518\n",
      "\t partial train loss (single batch): 0.034706\n",
      "\t partial train loss (single batch): 0.037519\n",
      "\t partial train loss (single batch): 0.034890\n",
      "\t partial train loss (single batch): 0.037160\n",
      "\t partial train loss (single batch): 0.035466\n",
      "\t partial train loss (single batch): 0.035643\n",
      "\t partial train loss (single batch): 0.037423\n",
      "\t partial train loss (single batch): 0.034442\n",
      "\t partial train loss (single batch): 0.035904\n",
      "\t partial train loss (single batch): 0.033696\n",
      "\t partial train loss (single batch): 0.036117\n",
      "\t partial train loss (single batch): 0.035800\n",
      "\t partial train loss (single batch): 0.036513\n",
      "\t partial train loss (single batch): 0.036399\n",
      "\t partial train loss (single batch): 0.033194\n",
      "\t partial train loss (single batch): 0.035892\n",
      "\t partial train loss (single batch): 0.035291\n",
      "\t partial train loss (single batch): 0.034351\n",
      "\t partial train loss (single batch): 0.037387\n",
      "\t partial train loss (single batch): 0.037870\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 5/10 - loss: 0.035486\n",
      "\n",
      "\n",
      "EPOCH 6/10\n",
      "\t partial train loss (single batch): 0.035365\n",
      "\t partial train loss (single batch): 0.034241\n",
      "\t partial train loss (single batch): 0.035547\n",
      "\t partial train loss (single batch): 0.035025\n",
      "\t partial train loss (single batch): 0.034971\n",
      "\t partial train loss (single batch): 0.036208\n",
      "\t partial train loss (single batch): 0.035523\n",
      "\t partial train loss (single batch): 0.034649\n",
      "\t partial train loss (single batch): 0.033513\n",
      "\t partial train loss (single batch): 0.035561\n",
      "\t partial train loss (single batch): 0.033338\n",
      "\t partial train loss (single batch): 0.035856\n",
      "\t partial train loss (single batch): 0.035384\n",
      "\t partial train loss (single batch): 0.035625\n",
      "\t partial train loss (single batch): 0.034285\n",
      "\t partial train loss (single batch): 0.032706\n",
      "\t partial train loss (single batch): 0.038162\n",
      "\t partial train loss (single batch): 0.036771\n",
      "\t partial train loss (single batch): 0.037209\n",
      "\t partial train loss (single batch): 0.036938\n",
      "\t partial train loss (single batch): 0.035210\n",
      "\t partial train loss (single batch): 0.035270\n",
      "\t partial train loss (single batch): 0.037252\n",
      "\t partial train loss (single batch): 0.036122\n",
      "\t partial train loss (single batch): 0.034283\n",
      "\t partial train loss (single batch): 0.036543\n",
      "\t partial train loss (single batch): 0.033897\n",
      "\t partial train loss (single batch): 0.037707\n",
      "\t partial train loss (single batch): 0.035038\n",
      "\t partial train loss (single batch): 0.036112\n",
      "\t partial train loss (single batch): 0.036918\n",
      "\t partial train loss (single batch): 0.034760\n",
      "\t partial train loss (single batch): 0.035797\n",
      "\t partial train loss (single batch): 0.033971\n",
      "\t partial train loss (single batch): 0.033649\n",
      "\t partial train loss (single batch): 0.034785\n",
      "\t partial train loss (single batch): 0.034308\n",
      "\t partial train loss (single batch): 0.033840\n",
      "\t partial train loss (single batch): 0.036823\n",
      "\t partial train loss (single batch): 0.036366\n",
      "\t partial train loss (single batch): 0.036166\n",
      "\t partial train loss (single batch): 0.033347\n",
      "\t partial train loss (single batch): 0.037067\n",
      "\t partial train loss (single batch): 0.034653\n",
      "\t partial train loss (single batch): 0.037093\n",
      "\t partial train loss (single batch): 0.035506\n",
      "\t partial train loss (single batch): 0.036891\n",
      "\t partial train loss (single batch): 0.036314\n",
      "\t partial train loss (single batch): 0.035358\n",
      "\t partial train loss (single batch): 0.035010\n",
      "\t partial train loss (single batch): 0.033423\n",
      "\t partial train loss (single batch): 0.035362\n",
      "\t partial train loss (single batch): 0.035596\n",
      "\t partial train loss (single batch): 0.034871\n",
      "\t partial train loss (single batch): 0.033737\n",
      "\t partial train loss (single batch): 0.035276\n",
      "\t partial train loss (single batch): 0.036162\n",
      "\t partial train loss (single batch): 0.035007\n",
      "\t partial train loss (single batch): 0.035463\n",
      "\t partial train loss (single batch): 0.035496\n",
      "\t partial train loss (single batch): 0.035101\n",
      "\t partial train loss (single batch): 0.035485\n",
      "\t partial train loss (single batch): 0.034883\n",
      "\t partial train loss (single batch): 0.035334\n",
      "\t partial train loss (single batch): 0.034381\n",
      "\t partial train loss (single batch): 0.034022\n",
      "\t partial train loss (single batch): 0.035174\n",
      "\t partial train loss (single batch): 0.037469\n",
      "\t partial train loss (single batch): 0.036727\n",
      "\t partial train loss (single batch): 0.034937\n",
      "\t partial train loss (single batch): 0.036423\n",
      "\t partial train loss (single batch): 0.033916\n",
      "\t partial train loss (single batch): 0.036783\n",
      "\t partial train loss (single batch): 0.035474\n",
      "\t partial train loss (single batch): 0.035709\n",
      "\t partial train loss (single batch): 0.035395\n",
      "\t partial train loss (single batch): 0.034675\n",
      "\t partial train loss (single batch): 0.037457\n",
      "\t partial train loss (single batch): 0.036648\n",
      "\t partial train loss (single batch): 0.036729\n",
      "\t partial train loss (single batch): 0.036943\n",
      "\t partial train loss (single batch): 0.035864\n",
      "\t partial train loss (single batch): 0.033932\n",
      "\t partial train loss (single batch): 0.036254\n",
      "\t partial train loss (single batch): 0.037762\n",
      "\t partial train loss (single batch): 0.036392\n",
      "\t partial train loss (single batch): 0.037088\n",
      "\t partial train loss (single batch): 0.034914\n",
      "\t partial train loss (single batch): 0.036463\n",
      "\t partial train loss (single batch): 0.034751\n",
      "\t partial train loss (single batch): 0.032888\n",
      "\t partial train loss (single batch): 0.034837\n",
      "\t partial train loss (single batch): 0.036854\n",
      "\t partial train loss (single batch): 0.034441\n",
      "\t partial train loss (single batch): 0.034894\n",
      "\t partial train loss (single batch): 0.034647\n",
      "\t partial train loss (single batch): 0.037098\n",
      "\t partial train loss (single batch): 0.034351\n",
      "\t partial train loss (single batch): 0.036101\n",
      "\t partial train loss (single batch): 0.036432\n",
      "\t partial train loss (single batch): 0.034523\n",
      "\t partial train loss (single batch): 0.036470\n",
      "\t partial train loss (single batch): 0.034776\n",
      "\t partial train loss (single batch): 0.034378\n",
      "\t partial train loss (single batch): 0.037326\n",
      "\t partial train loss (single batch): 0.036444\n",
      "\t partial train loss (single batch): 0.033493\n",
      "\t partial train loss (single batch): 0.030938\n",
      "\t partial train loss (single batch): 0.032404\n",
      "\t partial train loss (single batch): 0.036715\n",
      "\t partial train loss (single batch): 0.033426\n",
      "\t partial train loss (single batch): 0.035716\n",
      "\t partial train loss (single batch): 0.035585\n",
      "\t partial train loss (single batch): 0.035035\n",
      "\t partial train loss (single batch): 0.034039\n",
      "\t partial train loss (single batch): 0.035479\n",
      "\t partial train loss (single batch): 0.035973\n",
      "\t partial train loss (single batch): 0.034154\n",
      "\t partial train loss (single batch): 0.033700\n",
      "\t partial train loss (single batch): 0.034055\n",
      "\t partial train loss (single batch): 0.033658\n",
      "\t partial train loss (single batch): 0.035211\n",
      "\t partial train loss (single batch): 0.035289\n",
      "\t partial train loss (single batch): 0.035387\n",
      "\t partial train loss (single batch): 0.034023\n",
      "\t partial train loss (single batch): 0.035254\n",
      "\t partial train loss (single batch): 0.035696\n",
      "\t partial train loss (single batch): 0.035260\n",
      "\t partial train loss (single batch): 0.034808\n",
      "\t partial train loss (single batch): 0.034511\n",
      "\t partial train loss (single batch): 0.035470\n",
      "\t partial train loss (single batch): 0.035515\n",
      "\t partial train loss (single batch): 0.035708\n",
      "\t partial train loss (single batch): 0.033134\n",
      "\t partial train loss (single batch): 0.035610\n",
      "\t partial train loss (single batch): 0.037858\n",
      "\t partial train loss (single batch): 0.035854\n",
      "\t partial train loss (single batch): 0.035959\n",
      "\t partial train loss (single batch): 0.037060\n",
      "\t partial train loss (single batch): 0.036092\n",
      "\t partial train loss (single batch): 0.034431\n",
      "\t partial train loss (single batch): 0.036060\n",
      "\t partial train loss (single batch): 0.033168\n",
      "\t partial train loss (single batch): 0.035888\n",
      "\t partial train loss (single batch): 0.036885\n",
      "\t partial train loss (single batch): 0.038354\n",
      "\t partial train loss (single batch): 0.035496\n",
      "\t partial train loss (single batch): 0.033169\n",
      "\t partial train loss (single batch): 0.034192\n",
      "\t partial train loss (single batch): 0.034331\n",
      "\t partial train loss (single batch): 0.034702\n",
      "\t partial train loss (single batch): 0.036644\n",
      "\t partial train loss (single batch): 0.036434\n",
      "\t partial train loss (single batch): 0.037805\n",
      "\t partial train loss (single batch): 0.034653\n",
      "\t partial train loss (single batch): 0.034701\n",
      "\t partial train loss (single batch): 0.037817\n",
      "\t partial train loss (single batch): 0.037504\n",
      "\t partial train loss (single batch): 0.035324\n",
      "\t partial train loss (single batch): 0.034748\n",
      "\t partial train loss (single batch): 0.035696\n",
      "\t partial train loss (single batch): 0.036224\n",
      "\t partial train loss (single batch): 0.037830\n",
      "\t partial train loss (single batch): 0.035642\n",
      "\t partial train loss (single batch): 0.037104\n",
      "\t partial train loss (single batch): 0.034840\n",
      "\t partial train loss (single batch): 0.032382\n",
      "\t partial train loss (single batch): 0.033446\n",
      "\t partial train loss (single batch): 0.034083\n",
      "\t partial train loss (single batch): 0.035079\n",
      "\t partial train loss (single batch): 0.035931\n",
      "\t partial train loss (single batch): 0.035117\n",
      "\t partial train loss (single batch): 0.033906\n",
      "\t partial train loss (single batch): 0.036714\n",
      "\t partial train loss (single batch): 0.036182\n",
      "\t partial train loss (single batch): 0.034861\n",
      "\t partial train loss (single batch): 0.035508\n",
      "\t partial train loss (single batch): 0.035014\n",
      "\t partial train loss (single batch): 0.036155\n",
      "\t partial train loss (single batch): 0.036186\n",
      "\t partial train loss (single batch): 0.034622\n",
      "\t partial train loss (single batch): 0.034798\n",
      "\t partial train loss (single batch): 0.035863\n",
      "\t partial train loss (single batch): 0.034575\n",
      "\t partial train loss (single batch): 0.033743\n",
      "\t partial train loss (single batch): 0.035202\n",
      "\t partial train loss (single batch): 0.033377\n",
      "\t partial train loss (single batch): 0.033200\n",
      "\t partial train loss (single batch): 0.033649\n",
      "\t partial train loss (single batch): 0.035102\n",
      "\t partial train loss (single batch): 0.032959\n",
      "\t partial train loss (single batch): 0.033799\n",
      "\t partial train loss (single batch): 0.035331\n",
      "\t partial train loss (single batch): 0.035610\n",
      "\t partial train loss (single batch): 0.035462\n",
      "\t partial train loss (single batch): 0.035455\n",
      "\t partial train loss (single batch): 0.035217\n",
      "\t partial train loss (single batch): 0.035144\n",
      "\t partial train loss (single batch): 0.036021\n",
      "\t partial train loss (single batch): 0.035677\n",
      "\t partial train loss (single batch): 0.036110\n",
      "\t partial train loss (single batch): 0.034514\n",
      "\t partial train loss (single batch): 0.036767\n",
      "\t partial train loss (single batch): 0.036706\n",
      "\t partial train loss (single batch): 0.033343\n",
      "\t partial train loss (single batch): 0.036126\n",
      "\t partial train loss (single batch): 0.035838\n",
      "\t partial train loss (single batch): 0.034640\n",
      "\t partial train loss (single batch): 0.035588\n",
      "\t partial train loss (single batch): 0.036752\n",
      "\t partial train loss (single batch): 0.035490\n",
      "\t partial train loss (single batch): 0.035082\n",
      "\t partial train loss (single batch): 0.034528\n",
      "\t partial train loss (single batch): 0.033838\n",
      "\t partial train loss (single batch): 0.033979\n",
      "\t partial train loss (single batch): 0.035257\n",
      "\t partial train loss (single batch): 0.035660\n",
      "\t partial train loss (single batch): 0.035935\n",
      "\t partial train loss (single batch): 0.034965\n",
      "\t partial train loss (single batch): 0.033837\n",
      "\t partial train loss (single batch): 0.036720\n",
      "\t partial train loss (single batch): 0.035310\n",
      "\t partial train loss (single batch): 0.033020\n",
      "\t partial train loss (single batch): 0.034564\n",
      "\t partial train loss (single batch): 0.034517\n",
      "\t partial train loss (single batch): 0.037819\n",
      "\t partial train loss (single batch): 0.032538\n",
      "\t partial train loss (single batch): 0.034297\n",
      "\t partial train loss (single batch): 0.034618\n",
      "\t partial train loss (single batch): 0.037565\n",
      "\t partial train loss (single batch): 0.033950\n",
      "\t partial train loss (single batch): 0.035732\n",
      "\t partial train loss (single batch): 0.035582\n",
      "\t partial train loss (single batch): 0.034435\n",
      "\t partial train loss (single batch): 0.034622\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 6/10 - loss: 0.034640\n",
      "\n",
      "\n",
      "EPOCH 7/10\n",
      "\t partial train loss (single batch): 0.035917\n",
      "\t partial train loss (single batch): 0.035482\n",
      "\t partial train loss (single batch): 0.033909\n",
      "\t partial train loss (single batch): 0.035195\n",
      "\t partial train loss (single batch): 0.035126\n",
      "\t partial train loss (single batch): 0.035266\n",
      "\t partial train loss (single batch): 0.034933\n",
      "\t partial train loss (single batch): 0.035719\n",
      "\t partial train loss (single batch): 0.035844\n",
      "\t partial train loss (single batch): 0.033957\n",
      "\t partial train loss (single batch): 0.032654\n",
      "\t partial train loss (single batch): 0.032833\n",
      "\t partial train loss (single batch): 0.036692\n",
      "\t partial train loss (single batch): 0.035352\n",
      "\t partial train loss (single batch): 0.034590\n",
      "\t partial train loss (single batch): 0.034434\n",
      "\t partial train loss (single batch): 0.033044\n",
      "\t partial train loss (single batch): 0.037153\n",
      "\t partial train loss (single batch): 0.034566\n",
      "\t partial train loss (single batch): 0.036004\n",
      "\t partial train loss (single batch): 0.035248\n",
      "\t partial train loss (single batch): 0.035010\n",
      "\t partial train loss (single batch): 0.033857\n",
      "\t partial train loss (single batch): 0.032524\n",
      "\t partial train loss (single batch): 0.034322\n",
      "\t partial train loss (single batch): 0.035727\n",
      "\t partial train loss (single batch): 0.035580\n",
      "\t partial train loss (single batch): 0.033159\n",
      "\t partial train loss (single batch): 0.035733\n",
      "\t partial train loss (single batch): 0.035171\n",
      "\t partial train loss (single batch): 0.035006\n",
      "\t partial train loss (single batch): 0.034553\n",
      "\t partial train loss (single batch): 0.034302\n",
      "\t partial train loss (single batch): 0.035016\n",
      "\t partial train loss (single batch): 0.035366\n",
      "\t partial train loss (single batch): 0.034511\n",
      "\t partial train loss (single batch): 0.034483\n",
      "\t partial train loss (single batch): 0.033982\n",
      "\t partial train loss (single batch): 0.034742\n",
      "\t partial train loss (single batch): 0.036080\n",
      "\t partial train loss (single batch): 0.035208\n",
      "\t partial train loss (single batch): 0.033676\n",
      "\t partial train loss (single batch): 0.032936\n",
      "\t partial train loss (single batch): 0.034910\n",
      "\t partial train loss (single batch): 0.035578\n",
      "\t partial train loss (single batch): 0.035511\n",
      "\t partial train loss (single batch): 0.035404\n",
      "\t partial train loss (single batch): 0.034606\n",
      "\t partial train loss (single batch): 0.031271\n",
      "\t partial train loss (single batch): 0.033775\n",
      "\t partial train loss (single batch): 0.036035\n",
      "\t partial train loss (single batch): 0.035769\n",
      "\t partial train loss (single batch): 0.033803\n",
      "\t partial train loss (single batch): 0.036377\n",
      "\t partial train loss (single batch): 0.033084\n",
      "\t partial train loss (single batch): 0.035398\n",
      "\t partial train loss (single batch): 0.033441\n",
      "\t partial train loss (single batch): 0.033566\n",
      "\t partial train loss (single batch): 0.035159\n",
      "\t partial train loss (single batch): 0.037378\n",
      "\t partial train loss (single batch): 0.034480\n",
      "\t partial train loss (single batch): 0.035715\n",
      "\t partial train loss (single batch): 0.033625\n",
      "\t partial train loss (single batch): 0.034557\n",
      "\t partial train loss (single batch): 0.033480\n",
      "\t partial train loss (single batch): 0.035472\n",
      "\t partial train loss (single batch): 0.035180\n",
      "\t partial train loss (single batch): 0.034403\n",
      "\t partial train loss (single batch): 0.035245\n",
      "\t partial train loss (single batch): 0.034714\n",
      "\t partial train loss (single batch): 0.033528\n",
      "\t partial train loss (single batch): 0.034773\n",
      "\t partial train loss (single batch): 0.035211\n",
      "\t partial train loss (single batch): 0.033538\n",
      "\t partial train loss (single batch): 0.037020\n",
      "\t partial train loss (single batch): 0.034420\n",
      "\t partial train loss (single batch): 0.034054\n",
      "\t partial train loss (single batch): 0.035976\n",
      "\t partial train loss (single batch): 0.034781\n",
      "\t partial train loss (single batch): 0.036589\n",
      "\t partial train loss (single batch): 0.033728\n",
      "\t partial train loss (single batch): 0.033553\n",
      "\t partial train loss (single batch): 0.034866\n",
      "\t partial train loss (single batch): 0.036004\n",
      "\t partial train loss (single batch): 0.033571\n",
      "\t partial train loss (single batch): 0.034835\n",
      "\t partial train loss (single batch): 0.033819\n",
      "\t partial train loss (single batch): 0.034257\n",
      "\t partial train loss (single batch): 0.037287\n",
      "\t partial train loss (single batch): 0.033438\n",
      "\t partial train loss (single batch): 0.037314\n",
      "\t partial train loss (single batch): 0.034351\n",
      "\t partial train loss (single batch): 0.036304\n",
      "\t partial train loss (single batch): 0.034507\n",
      "\t partial train loss (single batch): 0.033709\n",
      "\t partial train loss (single batch): 0.036316\n",
      "\t partial train loss (single batch): 0.032272\n",
      "\t partial train loss (single batch): 0.033825\n",
      "\t partial train loss (single batch): 0.033222\n",
      "\t partial train loss (single batch): 0.034943\n",
      "\t partial train loss (single batch): 0.034214\n",
      "\t partial train loss (single batch): 0.036445\n",
      "\t partial train loss (single batch): 0.033907\n",
      "\t partial train loss (single batch): 0.033572\n",
      "\t partial train loss (single batch): 0.034504\n",
      "\t partial train loss (single batch): 0.034867\n",
      "\t partial train loss (single batch): 0.034904\n",
      "\t partial train loss (single batch): 0.034061\n",
      "\t partial train loss (single batch): 0.034859\n",
      "\t partial train loss (single batch): 0.034604\n",
      "\t partial train loss (single batch): 0.035025\n",
      "\t partial train loss (single batch): 0.035577\n",
      "\t partial train loss (single batch): 0.035625\n",
      "\t partial train loss (single batch): 0.032270\n",
      "\t partial train loss (single batch): 0.034194\n",
      "\t partial train loss (single batch): 0.035359\n",
      "\t partial train loss (single batch): 0.033459\n",
      "\t partial train loss (single batch): 0.035748\n",
      "\t partial train loss (single batch): 0.034485\n",
      "\t partial train loss (single batch): 0.037064\n",
      "\t partial train loss (single batch): 0.033961\n",
      "\t partial train loss (single batch): 0.034607\n",
      "\t partial train loss (single batch): 0.033962\n",
      "\t partial train loss (single batch): 0.032805\n",
      "\t partial train loss (single batch): 0.036320\n",
      "\t partial train loss (single batch): 0.033181\n",
      "\t partial train loss (single batch): 0.031948\n",
      "\t partial train loss (single batch): 0.032431\n",
      "\t partial train loss (single batch): 0.034625\n",
      "\t partial train loss (single batch): 0.033136\n",
      "\t partial train loss (single batch): 0.033320\n",
      "\t partial train loss (single batch): 0.033685\n",
      "\t partial train loss (single batch): 0.033496\n",
      "\t partial train loss (single batch): 0.032329\n",
      "\t partial train loss (single batch): 0.033428\n",
      "\t partial train loss (single batch): 0.033525\n",
      "\t partial train loss (single batch): 0.032417\n",
      "\t partial train loss (single batch): 0.033619\n",
      "\t partial train loss (single batch): 0.033472\n",
      "\t partial train loss (single batch): 0.035374\n",
      "\t partial train loss (single batch): 0.037646\n",
      "\t partial train loss (single batch): 0.033967\n",
      "\t partial train loss (single batch): 0.033957\n",
      "\t partial train loss (single batch): 0.034979\n",
      "\t partial train loss (single batch): 0.033773\n",
      "\t partial train loss (single batch): 0.033676\n",
      "\t partial train loss (single batch): 0.035246\n",
      "\t partial train loss (single batch): 0.034107\n",
      "\t partial train loss (single batch): 0.035823\n",
      "\t partial train loss (single batch): 0.032939\n",
      "\t partial train loss (single batch): 0.037460\n",
      "\t partial train loss (single batch): 0.036033\n",
      "\t partial train loss (single batch): 0.034571\n",
      "\t partial train loss (single batch): 0.034411\n",
      "\t partial train loss (single batch): 0.035531\n",
      "\t partial train loss (single batch): 0.034394\n",
      "\t partial train loss (single batch): 0.031501\n",
      "\t partial train loss (single batch): 0.033763\n",
      "\t partial train loss (single batch): 0.036356\n",
      "\t partial train loss (single batch): 0.033790\n",
      "\t partial train loss (single batch): 0.036015\n",
      "\t partial train loss (single batch): 0.032677\n",
      "\t partial train loss (single batch): 0.035039\n",
      "\t partial train loss (single batch): 0.033621\n",
      "\t partial train loss (single batch): 0.034193\n",
      "\t partial train loss (single batch): 0.032896\n",
      "\t partial train loss (single batch): 0.034478\n",
      "\t partial train loss (single batch): 0.035827\n",
      "\t partial train loss (single batch): 0.034881\n",
      "\t partial train loss (single batch): 0.035797\n",
      "\t partial train loss (single batch): 0.035018\n",
      "\t partial train loss (single batch): 0.034139\n",
      "\t partial train loss (single batch): 0.032476\n",
      "\t partial train loss (single batch): 0.032666\n",
      "\t partial train loss (single batch): 0.035373\n",
      "\t partial train loss (single batch): 0.035778\n",
      "\t partial train loss (single batch): 0.032838\n",
      "\t partial train loss (single batch): 0.034959\n",
      "\t partial train loss (single batch): 0.035305\n",
      "\t partial train loss (single batch): 0.032511\n",
      "\t partial train loss (single batch): 0.031912\n",
      "\t partial train loss (single batch): 0.034773\n",
      "\t partial train loss (single batch): 0.034493\n",
      "\t partial train loss (single batch): 0.035142\n",
      "\t partial train loss (single batch): 0.034369\n",
      "\t partial train loss (single batch): 0.036537\n",
      "\t partial train loss (single batch): 0.034076\n",
      "\t partial train loss (single batch): 0.034766\n",
      "\t partial train loss (single batch): 0.032963\n",
      "\t partial train loss (single batch): 0.035602\n",
      "\t partial train loss (single batch): 0.034606\n",
      "\t partial train loss (single batch): 0.035059\n",
      "\t partial train loss (single batch): 0.033913\n",
      "\t partial train loss (single batch): 0.035185\n",
      "\t partial train loss (single batch): 0.034222\n",
      "\t partial train loss (single batch): 0.035013\n",
      "\t partial train loss (single batch): 0.033664\n",
      "\t partial train loss (single batch): 0.034185\n",
      "\t partial train loss (single batch): 0.035035\n",
      "\t partial train loss (single batch): 0.034682\n",
      "\t partial train loss (single batch): 0.035266\n",
      "\t partial train loss (single batch): 0.035769\n",
      "\t partial train loss (single batch): 0.032957\n",
      "\t partial train loss (single batch): 0.033569\n",
      "\t partial train loss (single batch): 0.033538\n",
      "\t partial train loss (single batch): 0.036975\n",
      "\t partial train loss (single batch): 0.035013\n",
      "\t partial train loss (single batch): 0.035024\n",
      "\t partial train loss (single batch): 0.035804\n",
      "\t partial train loss (single batch): 0.036230\n",
      "\t partial train loss (single batch): 0.035892\n",
      "\t partial train loss (single batch): 0.033585\n",
      "\t partial train loss (single batch): 0.032502\n",
      "\t partial train loss (single batch): 0.034663\n",
      "\t partial train loss (single batch): 0.036021\n",
      "\t partial train loss (single batch): 0.035209\n",
      "\t partial train loss (single batch): 0.034469\n",
      "\t partial train loss (single batch): 0.033039\n",
      "\t partial train loss (single batch): 0.034603\n",
      "\t partial train loss (single batch): 0.033561\n",
      "\t partial train loss (single batch): 0.035220\n",
      "\t partial train loss (single batch): 0.034652\n",
      "\t partial train loss (single batch): 0.032515\n",
      "\t partial train loss (single batch): 0.034122\n",
      "\t partial train loss (single batch): 0.033616\n",
      "\t partial train loss (single batch): 0.034685\n",
      "\t partial train loss (single batch): 0.031921\n",
      "\t partial train loss (single batch): 0.034917\n",
      "\t partial train loss (single batch): 0.033780\n",
      "\t partial train loss (single batch): 0.035120\n",
      "\t partial train loss (single batch): 0.032945\n",
      "\t partial train loss (single batch): 0.034247\n",
      "\t partial train loss (single batch): 0.032299\n",
      "\t partial train loss (single batch): 0.033466\n",
      "\t partial train loss (single batch): 0.034891\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 7/10 - loss: 0.033909\n",
      "\n",
      "\n",
      "EPOCH 8/10\n",
      "\t partial train loss (single batch): 0.032829\n",
      "\t partial train loss (single batch): 0.033394\n",
      "\t partial train loss (single batch): 0.033299\n",
      "\t partial train loss (single batch): 0.035636\n",
      "\t partial train loss (single batch): 0.032220\n",
      "\t partial train loss (single batch): 0.033599\n",
      "\t partial train loss (single batch): 0.033099\n",
      "\t partial train loss (single batch): 0.034045\n",
      "\t partial train loss (single batch): 0.033863\n",
      "\t partial train loss (single batch): 0.034074\n",
      "\t partial train loss (single batch): 0.032774\n",
      "\t partial train loss (single batch): 0.034017\n",
      "\t partial train loss (single batch): 0.035353\n",
      "\t partial train loss (single batch): 0.035423\n",
      "\t partial train loss (single batch): 0.032459\n",
      "\t partial train loss (single batch): 0.034136\n",
      "\t partial train loss (single batch): 0.034495\n",
      "\t partial train loss (single batch): 0.033964\n",
      "\t partial train loss (single batch): 0.035037\n",
      "\t partial train loss (single batch): 0.034849\n",
      "\t partial train loss (single batch): 0.035183\n",
      "\t partial train loss (single batch): 0.034186\n",
      "\t partial train loss (single batch): 0.034090\n",
      "\t partial train loss (single batch): 0.033348\n",
      "\t partial train loss (single batch): 0.036263\n",
      "\t partial train loss (single batch): 0.034786\n",
      "\t partial train loss (single batch): 0.036046\n",
      "\t partial train loss (single batch): 0.032529\n",
      "\t partial train loss (single batch): 0.034572\n",
      "\t partial train loss (single batch): 0.034885\n",
      "\t partial train loss (single batch): 0.034475\n",
      "\t partial train loss (single batch): 0.033470\n",
      "\t partial train loss (single batch): 0.035485\n",
      "\t partial train loss (single batch): 0.032087\n",
      "\t partial train loss (single batch): 0.034467\n",
      "\t partial train loss (single batch): 0.035416\n",
      "\t partial train loss (single batch): 0.033228\n",
      "\t partial train loss (single batch): 0.033405\n",
      "\t partial train loss (single batch): 0.032281\n",
      "\t partial train loss (single batch): 0.034907\n",
      "\t partial train loss (single batch): 0.033262\n",
      "\t partial train loss (single batch): 0.033247\n",
      "\t partial train loss (single batch): 0.034826\n",
      "\t partial train loss (single batch): 0.033818\n",
      "\t partial train loss (single batch): 0.034259\n",
      "\t partial train loss (single batch): 0.034766\n",
      "\t partial train loss (single batch): 0.035732\n",
      "\t partial train loss (single batch): 0.035751\n",
      "\t partial train loss (single batch): 0.032998\n",
      "\t partial train loss (single batch): 0.037153\n",
      "\t partial train loss (single batch): 0.033708\n",
      "\t partial train loss (single batch): 0.034553\n",
      "\t partial train loss (single batch): 0.035426\n",
      "\t partial train loss (single batch): 0.032871\n",
      "\t partial train loss (single batch): 0.032849\n",
      "\t partial train loss (single batch): 0.031850\n",
      "\t partial train loss (single batch): 0.033121\n",
      "\t partial train loss (single batch): 0.035628\n",
      "\t partial train loss (single batch): 0.034338\n",
      "\t partial train loss (single batch): 0.033910\n",
      "\t partial train loss (single batch): 0.032053\n",
      "\t partial train loss (single batch): 0.033479\n",
      "\t partial train loss (single batch): 0.032322\n",
      "\t partial train loss (single batch): 0.034714\n",
      "\t partial train loss (single batch): 0.036219\n",
      "\t partial train loss (single batch): 0.032691\n",
      "\t partial train loss (single batch): 0.034854\n",
      "\t partial train loss (single batch): 0.033475\n",
      "\t partial train loss (single batch): 0.034148\n",
      "\t partial train loss (single batch): 0.032400\n",
      "\t partial train loss (single batch): 0.035250\n",
      "\t partial train loss (single batch): 0.033249\n",
      "\t partial train loss (single batch): 0.034314\n",
      "\t partial train loss (single batch): 0.033470\n",
      "\t partial train loss (single batch): 0.035661\n",
      "\t partial train loss (single batch): 0.033663\n",
      "\t partial train loss (single batch): 0.034252\n",
      "\t partial train loss (single batch): 0.035081\n",
      "\t partial train loss (single batch): 0.033372\n",
      "\t partial train loss (single batch): 0.032551\n",
      "\t partial train loss (single batch): 0.034417\n",
      "\t partial train loss (single batch): 0.032709\n",
      "\t partial train loss (single batch): 0.031485\n",
      "\t partial train loss (single batch): 0.034125\n",
      "\t partial train loss (single batch): 0.033780\n",
      "\t partial train loss (single batch): 0.034170\n",
      "\t partial train loss (single batch): 0.033448\n",
      "\t partial train loss (single batch): 0.034158\n",
      "\t partial train loss (single batch): 0.032883\n",
      "\t partial train loss (single batch): 0.033856\n",
      "\t partial train loss (single batch): 0.033114\n",
      "\t partial train loss (single batch): 0.035318\n",
      "\t partial train loss (single batch): 0.033170\n",
      "\t partial train loss (single batch): 0.034075\n",
      "\t partial train loss (single batch): 0.034852\n",
      "\t partial train loss (single batch): 0.034965\n",
      "\t partial train loss (single batch): 0.034753\n",
      "\t partial train loss (single batch): 0.034206\n",
      "\t partial train loss (single batch): 0.034038\n",
      "\t partial train loss (single batch): 0.032946\n",
      "\t partial train loss (single batch): 0.034054\n",
      "\t partial train loss (single batch): 0.032824\n",
      "\t partial train loss (single batch): 0.034422\n",
      "\t partial train loss (single batch): 0.032723\n",
      "\t partial train loss (single batch): 0.034860\n",
      "\t partial train loss (single batch): 0.033177\n",
      "\t partial train loss (single batch): 0.034634\n",
      "\t partial train loss (single batch): 0.034046\n",
      "\t partial train loss (single batch): 0.031933\n",
      "\t partial train loss (single batch): 0.034529\n",
      "\t partial train loss (single batch): 0.033358\n",
      "\t partial train loss (single batch): 0.032432\n",
      "\t partial train loss (single batch): 0.034851\n",
      "\t partial train loss (single batch): 0.033815\n",
      "\t partial train loss (single batch): 0.035290\n",
      "\t partial train loss (single batch): 0.033453\n",
      "\t partial train loss (single batch): 0.032839\n",
      "\t partial train loss (single batch): 0.036324\n",
      "\t partial train loss (single batch): 0.034436\n",
      "\t partial train loss (single batch): 0.033748\n",
      "\t partial train loss (single batch): 0.033018\n",
      "\t partial train loss (single batch): 0.034621\n",
      "\t partial train loss (single batch): 0.032604\n",
      "\t partial train loss (single batch): 0.033564\n",
      "\t partial train loss (single batch): 0.032627\n",
      "\t partial train loss (single batch): 0.035580\n",
      "\t partial train loss (single batch): 0.033875\n",
      "\t partial train loss (single batch): 0.032151\n",
      "\t partial train loss (single batch): 0.032385\n",
      "\t partial train loss (single batch): 0.036989\n",
      "\t partial train loss (single batch): 0.033327\n",
      "\t partial train loss (single batch): 0.033016\n",
      "\t partial train loss (single batch): 0.033885\n",
      "\t partial train loss (single batch): 0.035298\n",
      "\t partial train loss (single batch): 0.034160\n",
      "\t partial train loss (single batch): 0.034146\n",
      "\t partial train loss (single batch): 0.034870\n",
      "\t partial train loss (single batch): 0.032977\n",
      "\t partial train loss (single batch): 0.034798\n",
      "\t partial train loss (single batch): 0.032808\n",
      "\t partial train loss (single batch): 0.032615\n",
      "\t partial train loss (single batch): 0.034975\n",
      "\t partial train loss (single batch): 0.035892\n",
      "\t partial train loss (single batch): 0.036853\n",
      "\t partial train loss (single batch): 0.033042\n",
      "\t partial train loss (single batch): 0.035529\n",
      "\t partial train loss (single batch): 0.033322\n",
      "\t partial train loss (single batch): 0.033301\n",
      "\t partial train loss (single batch): 0.033689\n",
      "\t partial train loss (single batch): 0.032960\n",
      "\t partial train loss (single batch): 0.033592\n",
      "\t partial train loss (single batch): 0.032173\n",
      "\t partial train loss (single batch): 0.031924\n",
      "\t partial train loss (single batch): 0.034178\n",
      "\t partial train loss (single batch): 0.032084\n",
      "\t partial train loss (single batch): 0.033168\n",
      "\t partial train loss (single batch): 0.033002\n",
      "\t partial train loss (single batch): 0.034761\n",
      "\t partial train loss (single batch): 0.036010\n",
      "\t partial train loss (single batch): 0.034238\n",
      "\t partial train loss (single batch): 0.034983\n",
      "\t partial train loss (single batch): 0.034045\n",
      "\t partial train loss (single batch): 0.032980\n",
      "\t partial train loss (single batch): 0.035690\n",
      "\t partial train loss (single batch): 0.032149\n",
      "\t partial train loss (single batch): 0.034215\n",
      "\t partial train loss (single batch): 0.032789\n",
      "\t partial train loss (single batch): 0.035445\n",
      "\t partial train loss (single batch): 0.033886\n",
      "\t partial train loss (single batch): 0.035315\n",
      "\t partial train loss (single batch): 0.031964\n",
      "\t partial train loss (single batch): 0.033914\n",
      "\t partial train loss (single batch): 0.033678\n",
      "\t partial train loss (single batch): 0.034131\n",
      "\t partial train loss (single batch): 0.032139\n",
      "\t partial train loss (single batch): 0.034055\n",
      "\t partial train loss (single batch): 0.034138\n",
      "\t partial train loss (single batch): 0.032627\n",
      "\t partial train loss (single batch): 0.032682\n",
      "\t partial train loss (single batch): 0.034587\n",
      "\t partial train loss (single batch): 0.033740\n",
      "\t partial train loss (single batch): 0.033349\n",
      "\t partial train loss (single batch): 0.034263\n",
      "\t partial train loss (single batch): 0.034640\n",
      "\t partial train loss (single batch): 0.035520\n",
      "\t partial train loss (single batch): 0.033811\n",
      "\t partial train loss (single batch): 0.034568\n",
      "\t partial train loss (single batch): 0.031940\n",
      "\t partial train loss (single batch): 0.035049\n",
      "\t partial train loss (single batch): 0.033442\n",
      "\t partial train loss (single batch): 0.033741\n",
      "\t partial train loss (single batch): 0.034569\n",
      "\t partial train loss (single batch): 0.034300\n",
      "\t partial train loss (single batch): 0.033699\n",
      "\t partial train loss (single batch): 0.036233\n",
      "\t partial train loss (single batch): 0.030376\n",
      "\t partial train loss (single batch): 0.033715\n",
      "\t partial train loss (single batch): 0.033308\n",
      "\t partial train loss (single batch): 0.035112\n",
      "\t partial train loss (single batch): 0.032874\n",
      "\t partial train loss (single batch): 0.032908\n",
      "\t partial train loss (single batch): 0.033572\n",
      "\t partial train loss (single batch): 0.033181\n",
      "\t partial train loss (single batch): 0.033758\n",
      "\t partial train loss (single batch): 0.033207\n",
      "\t partial train loss (single batch): 0.032366\n",
      "\t partial train loss (single batch): 0.035206\n",
      "\t partial train loss (single batch): 0.034548\n",
      "\t partial train loss (single batch): 0.034490\n",
      "\t partial train loss (single batch): 0.034586\n",
      "\t partial train loss (single batch): 0.033850\n",
      "\t partial train loss (single batch): 0.034338\n",
      "\t partial train loss (single batch): 0.031561\n",
      "\t partial train loss (single batch): 0.032040\n",
      "\t partial train loss (single batch): 0.033420\n",
      "\t partial train loss (single batch): 0.034216\n",
      "\t partial train loss (single batch): 0.033634\n",
      "\t partial train loss (single batch): 0.035583\n",
      "\t partial train loss (single batch): 0.034802\n",
      "\t partial train loss (single batch): 0.034891\n",
      "\t partial train loss (single batch): 0.034225\n",
      "\t partial train loss (single batch): 0.033127\n",
      "\t partial train loss (single batch): 0.033517\n",
      "\t partial train loss (single batch): 0.031682\n",
      "\t partial train loss (single batch): 0.035274\n",
      "\t partial train loss (single batch): 0.032312\n",
      "\t partial train loss (single batch): 0.032731\n",
      "\t partial train loss (single batch): 0.032991\n",
      "\t partial train loss (single batch): 0.035361\n",
      "\t partial train loss (single batch): 0.035040\n",
      "\t partial train loss (single batch): 0.032430\n",
      "\t partial train loss (single batch): 0.033573\n",
      "\t partial train loss (single batch): 0.033099\n",
      "\t partial train loss (single batch): 0.032472\n",
      "\t partial train loss (single batch): 0.034671\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 8/10 - loss: 0.033275\n",
      "\n",
      "\n",
      "EPOCH 9/10\n",
      "\t partial train loss (single batch): 0.033127\n",
      "\t partial train loss (single batch): 0.034303\n",
      "\t partial train loss (single batch): 0.033604\n",
      "\t partial train loss (single batch): 0.031647\n",
      "\t partial train loss (single batch): 0.030600\n",
      "\t partial train loss (single batch): 0.033847\n",
      "\t partial train loss (single batch): 0.035086\n",
      "\t partial train loss (single batch): 0.034779\n",
      "\t partial train loss (single batch): 0.033086\n",
      "\t partial train loss (single batch): 0.034981\n",
      "\t partial train loss (single batch): 0.034436\n",
      "\t partial train loss (single batch): 0.032453\n",
      "\t partial train loss (single batch): 0.034294\n",
      "\t partial train loss (single batch): 0.033075\n",
      "\t partial train loss (single batch): 0.032342\n",
      "\t partial train loss (single batch): 0.032841\n",
      "\t partial train loss (single batch): 0.033583\n",
      "\t partial train loss (single batch): 0.033973\n",
      "\t partial train loss (single batch): 0.031253\n",
      "\t partial train loss (single batch): 0.032179\n",
      "\t partial train loss (single batch): 0.033825\n",
      "\t partial train loss (single batch): 0.032813\n",
      "\t partial train loss (single batch): 0.033781\n",
      "\t partial train loss (single batch): 0.033013\n",
      "\t partial train loss (single batch): 0.032839\n",
      "\t partial train loss (single batch): 0.034468\n",
      "\t partial train loss (single batch): 0.034084\n",
      "\t partial train loss (single batch): 0.036150\n",
      "\t partial train loss (single batch): 0.034079\n",
      "\t partial train loss (single batch): 0.033661\n",
      "\t partial train loss (single batch): 0.032635\n",
      "\t partial train loss (single batch): 0.034685\n",
      "\t partial train loss (single batch): 0.031510\n",
      "\t partial train loss (single batch): 0.034210\n",
      "\t partial train loss (single batch): 0.034359\n",
      "\t partial train loss (single batch): 0.035004\n",
      "\t partial train loss (single batch): 0.035229\n",
      "\t partial train loss (single batch): 0.034019\n",
      "\t partial train loss (single batch): 0.034133\n",
      "\t partial train loss (single batch): 0.033629\n",
      "\t partial train loss (single batch): 0.034250\n",
      "\t partial train loss (single batch): 0.033738\n",
      "\t partial train loss (single batch): 0.033091\n",
      "\t partial train loss (single batch): 0.033360\n",
      "\t partial train loss (single batch): 0.033641\n",
      "\t partial train loss (single batch): 0.033972\n",
      "\t partial train loss (single batch): 0.033211\n",
      "\t partial train loss (single batch): 0.035150\n",
      "\t partial train loss (single batch): 0.033833\n",
      "\t partial train loss (single batch): 0.033510\n",
      "\t partial train loss (single batch): 0.032926\n",
      "\t partial train loss (single batch): 0.032206\n",
      "\t partial train loss (single batch): 0.031477\n",
      "\t partial train loss (single batch): 0.034889\n",
      "\t partial train loss (single batch): 0.033456\n",
      "\t partial train loss (single batch): 0.033582\n",
      "\t partial train loss (single batch): 0.033036\n",
      "\t partial train loss (single batch): 0.032502\n",
      "\t partial train loss (single batch): 0.033078\n",
      "\t partial train loss (single batch): 0.032767\n",
      "\t partial train loss (single batch): 0.033650\n",
      "\t partial train loss (single batch): 0.034779\n",
      "\t partial train loss (single batch): 0.032083\n",
      "\t partial train loss (single batch): 0.035022\n",
      "\t partial train loss (single batch): 0.033684\n",
      "\t partial train loss (single batch): 0.032748\n",
      "\t partial train loss (single batch): 0.033352\n",
      "\t partial train loss (single batch): 0.032096\n",
      "\t partial train loss (single batch): 0.034280\n",
      "\t partial train loss (single batch): 0.034031\n",
      "\t partial train loss (single batch): 0.032137\n",
      "\t partial train loss (single batch): 0.034227\n",
      "\t partial train loss (single batch): 0.033602\n",
      "\t partial train loss (single batch): 0.034576\n",
      "\t partial train loss (single batch): 0.033975\n",
      "\t partial train loss (single batch): 0.034681\n",
      "\t partial train loss (single batch): 0.031813\n",
      "\t partial train loss (single batch): 0.033880\n",
      "\t partial train loss (single batch): 0.033306\n",
      "\t partial train loss (single batch): 0.034533\n",
      "\t partial train loss (single batch): 0.033649\n",
      "\t partial train loss (single batch): 0.033356\n",
      "\t partial train loss (single batch): 0.033611\n",
      "\t partial train loss (single batch): 0.034101\n",
      "\t partial train loss (single batch): 0.034238\n",
      "\t partial train loss (single batch): 0.032081\n",
      "\t partial train loss (single batch): 0.032561\n",
      "\t partial train loss (single batch): 0.032780\n",
      "\t partial train loss (single batch): 0.033175\n",
      "\t partial train loss (single batch): 0.034111\n",
      "\t partial train loss (single batch): 0.034440\n",
      "\t partial train loss (single batch): 0.033482\n",
      "\t partial train loss (single batch): 0.033233\n",
      "\t partial train loss (single batch): 0.034969\n",
      "\t partial train loss (single batch): 0.034253\n",
      "\t partial train loss (single batch): 0.033565\n",
      "\t partial train loss (single batch): 0.033352\n",
      "\t partial train loss (single batch): 0.032625\n",
      "\t partial train loss (single batch): 0.032921\n",
      "\t partial train loss (single batch): 0.032503\n",
      "\t partial train loss (single batch): 0.032931\n",
      "\t partial train loss (single batch): 0.032883\n",
      "\t partial train loss (single batch): 0.034943\n",
      "\t partial train loss (single batch): 0.032821\n",
      "\t partial train loss (single batch): 0.032657\n",
      "\t partial train loss (single batch): 0.033944\n",
      "\t partial train loss (single batch): 0.035006\n",
      "\t partial train loss (single batch): 0.034993\n",
      "\t partial train loss (single batch): 0.031193\n",
      "\t partial train loss (single batch): 0.032532\n",
      "\t partial train loss (single batch): 0.032718\n",
      "\t partial train loss (single batch): 0.031646\n",
      "\t partial train loss (single batch): 0.030775\n",
      "\t partial train loss (single batch): 0.033517\n",
      "\t partial train loss (single batch): 0.034445\n",
      "\t partial train loss (single batch): 0.033266\n",
      "\t partial train loss (single batch): 0.034868\n",
      "\t partial train loss (single batch): 0.031980\n",
      "\t partial train loss (single batch): 0.034975\n",
      "\t partial train loss (single batch): 0.032462\n",
      "\t partial train loss (single batch): 0.032710\n",
      "\t partial train loss (single batch): 0.031762\n",
      "\t partial train loss (single batch): 0.032939\n",
      "\t partial train loss (single batch): 0.032727\n",
      "\t partial train loss (single batch): 0.034682\n",
      "\t partial train loss (single batch): 0.033154\n",
      "\t partial train loss (single batch): 0.033350\n",
      "\t partial train loss (single batch): 0.035428\n",
      "\t partial train loss (single batch): 0.033958\n",
      "\t partial train loss (single batch): 0.032297\n",
      "\t partial train loss (single batch): 0.032867\n",
      "\t partial train loss (single batch): 0.032376\n",
      "\t partial train loss (single batch): 0.033672\n",
      "\t partial train loss (single batch): 0.032710\n",
      "\t partial train loss (single batch): 0.033543\n",
      "\t partial train loss (single batch): 0.030807\n",
      "\t partial train loss (single batch): 0.035277\n",
      "\t partial train loss (single batch): 0.032358\n",
      "\t partial train loss (single batch): 0.032649\n",
      "\t partial train loss (single batch): 0.031342\n",
      "\t partial train loss (single batch): 0.032721\n",
      "\t partial train loss (single batch): 0.032883\n",
      "\t partial train loss (single batch): 0.033236\n",
      "\t partial train loss (single batch): 0.032543\n",
      "\t partial train loss (single batch): 0.034729\n",
      "\t partial train loss (single batch): 0.031767\n",
      "\t partial train loss (single batch): 0.033251\n",
      "\t partial train loss (single batch): 0.032612\n",
      "\t partial train loss (single batch): 0.035823\n",
      "\t partial train loss (single batch): 0.033329\n",
      "\t partial train loss (single batch): 0.034882\n",
      "\t partial train loss (single batch): 0.033820\n",
      "\t partial train loss (single batch): 0.032829\n",
      "\t partial train loss (single batch): 0.032191\n",
      "\t partial train loss (single batch): 0.033434\n",
      "\t partial train loss (single batch): 0.034047\n",
      "\t partial train loss (single batch): 0.034154\n",
      "\t partial train loss (single batch): 0.031868\n",
      "\t partial train loss (single batch): 0.032327\n",
      "\t partial train loss (single batch): 0.032156\n",
      "\t partial train loss (single batch): 0.035034\n",
      "\t partial train loss (single batch): 0.033990\n",
      "\t partial train loss (single batch): 0.033011\n",
      "\t partial train loss (single batch): 0.031238\n",
      "\t partial train loss (single batch): 0.033604\n",
      "\t partial train loss (single batch): 0.034929\n",
      "\t partial train loss (single batch): 0.034717\n",
      "\t partial train loss (single batch): 0.035521\n",
      "\t partial train loss (single batch): 0.032074\n",
      "\t partial train loss (single batch): 0.034430\n",
      "\t partial train loss (single batch): 0.035244\n",
      "\t partial train loss (single batch): 0.032173\n",
      "\t partial train loss (single batch): 0.033163\n",
      "\t partial train loss (single batch): 0.033318\n",
      "\t partial train loss (single batch): 0.031561\n",
      "\t partial train loss (single batch): 0.032610\n",
      "\t partial train loss (single batch): 0.033476\n",
      "\t partial train loss (single batch): 0.033668\n",
      "\t partial train loss (single batch): 0.033573\n",
      "\t partial train loss (single batch): 0.033402\n",
      "\t partial train loss (single batch): 0.031907\n",
      "\t partial train loss (single batch): 0.033683\n",
      "\t partial train loss (single batch): 0.034236\n",
      "\t partial train loss (single batch): 0.034024\n",
      "\t partial train loss (single batch): 0.033101\n",
      "\t partial train loss (single batch): 0.036000\n",
      "\t partial train loss (single batch): 0.033814\n",
      "\t partial train loss (single batch): 0.033925\n",
      "\t partial train loss (single batch): 0.031659\n",
      "\t partial train loss (single batch): 0.032616\n",
      "\t partial train loss (single batch): 0.032288\n",
      "\t partial train loss (single batch): 0.030554\n",
      "\t partial train loss (single batch): 0.032120\n",
      "\t partial train loss (single batch): 0.031719\n",
      "\t partial train loss (single batch): 0.033828\n",
      "\t partial train loss (single batch): 0.033405\n",
      "\t partial train loss (single batch): 0.032248\n",
      "\t partial train loss (single batch): 0.031584\n",
      "\t partial train loss (single batch): 0.031951\n",
      "\t partial train loss (single batch): 0.035046\n",
      "\t partial train loss (single batch): 0.035051\n",
      "\t partial train loss (single batch): 0.033808\n",
      "\t partial train loss (single batch): 0.032664\n",
      "\t partial train loss (single batch): 0.033712\n",
      "\t partial train loss (single batch): 0.033101\n",
      "\t partial train loss (single batch): 0.034225\n",
      "\t partial train loss (single batch): 0.034546\n",
      "\t partial train loss (single batch): 0.032695\n",
      "\t partial train loss (single batch): 0.032870\n",
      "\t partial train loss (single batch): 0.034207\n",
      "\t partial train loss (single batch): 0.035105\n",
      "\t partial train loss (single batch): 0.034558\n",
      "\t partial train loss (single batch): 0.032626\n",
      "\t partial train loss (single batch): 0.034828\n",
      "\t partial train loss (single batch): 0.033173\n",
      "\t partial train loss (single batch): 0.032722\n",
      "\t partial train loss (single batch): 0.032596\n",
      "\t partial train loss (single batch): 0.032309\n",
      "\t partial train loss (single batch): 0.032028\n",
      "\t partial train loss (single batch): 0.032632\n",
      "\t partial train loss (single batch): 0.033156\n",
      "\t partial train loss (single batch): 0.031373\n",
      "\t partial train loss (single batch): 0.034435\n",
      "\t partial train loss (single batch): 0.031946\n",
      "\t partial train loss (single batch): 0.034637\n",
      "\t partial train loss (single batch): 0.032600\n",
      "\t partial train loss (single batch): 0.033866\n",
      "\t partial train loss (single batch): 0.032055\n",
      "\t partial train loss (single batch): 0.032290\n",
      "\t partial train loss (single batch): 0.032836\n",
      "\t partial train loss (single batch): 0.031763\n",
      "\t partial train loss (single batch): 0.032259\n",
      "\t partial train loss (single batch): 0.033633\n",
      "\t partial train loss (single batch): 0.033215\n",
      "\t partial train loss (single batch): 0.037259\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 9/10 - loss: 0.032943\n",
      "\n",
      "\n",
      "EPOCH 10/10\n",
      "\t partial train loss (single batch): 0.030347\n",
      "\t partial train loss (single batch): 0.032649\n",
      "\t partial train loss (single batch): 0.034278\n",
      "\t partial train loss (single batch): 0.033055\n",
      "\t partial train loss (single batch): 0.033733\n",
      "\t partial train loss (single batch): 0.032145\n",
      "\t partial train loss (single batch): 0.033766\n",
      "\t partial train loss (single batch): 0.031783\n",
      "\t partial train loss (single batch): 0.035334\n",
      "\t partial train loss (single batch): 0.032541\n",
      "\t partial train loss (single batch): 0.034160\n",
      "\t partial train loss (single batch): 0.034906\n",
      "\t partial train loss (single batch): 0.033815\n",
      "\t partial train loss (single batch): 0.031531\n",
      "\t partial train loss (single batch): 0.034693\n",
      "\t partial train loss (single batch): 0.034018\n",
      "\t partial train loss (single batch): 0.033583\n",
      "\t partial train loss (single batch): 0.034503\n",
      "\t partial train loss (single batch): 0.033966\n",
      "\t partial train loss (single batch): 0.032257\n",
      "\t partial train loss (single batch): 0.032509\n",
      "\t partial train loss (single batch): 0.032584\n",
      "\t partial train loss (single batch): 0.032228\n",
      "\t partial train loss (single batch): 0.033917\n",
      "\t partial train loss (single batch): 0.034075\n",
      "\t partial train loss (single batch): 0.032497\n",
      "\t partial train loss (single batch): 0.032684\n",
      "\t partial train loss (single batch): 0.032456\n",
      "\t partial train loss (single batch): 0.033491\n",
      "\t partial train loss (single batch): 0.031359\n",
      "\t partial train loss (single batch): 0.033386\n",
      "\t partial train loss (single batch): 0.033846\n",
      "\t partial train loss (single batch): 0.032177\n",
      "\t partial train loss (single batch): 0.031298\n",
      "\t partial train loss (single batch): 0.031512\n",
      "\t partial train loss (single batch): 0.031621\n",
      "\t partial train loss (single batch): 0.033775\n",
      "\t partial train loss (single batch): 0.034111\n",
      "\t partial train loss (single batch): 0.033294\n",
      "\t partial train loss (single batch): 0.033589\n",
      "\t partial train loss (single batch): 0.033978\n",
      "\t partial train loss (single batch): 0.033733\n",
      "\t partial train loss (single batch): 0.032149\n",
      "\t partial train loss (single batch): 0.033956\n",
      "\t partial train loss (single batch): 0.033798\n",
      "\t partial train loss (single batch): 0.031924\n",
      "\t partial train loss (single batch): 0.034781\n",
      "\t partial train loss (single batch): 0.033977\n",
      "\t partial train loss (single batch): 0.032249\n",
      "\t partial train loss (single batch): 0.032667\n",
      "\t partial train loss (single batch): 0.032366\n",
      "\t partial train loss (single batch): 0.033765\n",
      "\t partial train loss (single batch): 0.034664\n",
      "\t partial train loss (single batch): 0.031766\n",
      "\t partial train loss (single batch): 0.036903\n",
      "\t partial train loss (single batch): 0.033473\n",
      "\t partial train loss (single batch): 0.032701\n",
      "\t partial train loss (single batch): 0.032588\n",
      "\t partial train loss (single batch): 0.034292\n",
      "\t partial train loss (single batch): 0.031599\n",
      "\t partial train loss (single batch): 0.030590\n",
      "\t partial train loss (single batch): 0.030502\n",
      "\t partial train loss (single batch): 0.032487\n",
      "\t partial train loss (single batch): 0.033462\n",
      "\t partial train loss (single batch): 0.035262\n",
      "\t partial train loss (single batch): 0.031193\n",
      "\t partial train loss (single batch): 0.032106\n",
      "\t partial train loss (single batch): 0.034889\n",
      "\t partial train loss (single batch): 0.033333\n",
      "\t partial train loss (single batch): 0.033422\n",
      "\t partial train loss (single batch): 0.033601\n",
      "\t partial train loss (single batch): 0.031676\n",
      "\t partial train loss (single batch): 0.031591\n",
      "\t partial train loss (single batch): 0.034233\n",
      "\t partial train loss (single batch): 0.032016\n",
      "\t partial train loss (single batch): 0.034081\n",
      "\t partial train loss (single batch): 0.032879\n",
      "\t partial train loss (single batch): 0.034196\n",
      "\t partial train loss (single batch): 0.032658\n",
      "\t partial train loss (single batch): 0.033296\n",
      "\t partial train loss (single batch): 0.033691\n",
      "\t partial train loss (single batch): 0.034400\n",
      "\t partial train loss (single batch): 0.033140\n",
      "\t partial train loss (single batch): 0.032399\n",
      "\t partial train loss (single batch): 0.034530\n",
      "\t partial train loss (single batch): 0.032562\n",
      "\t partial train loss (single batch): 0.034316\n",
      "\t partial train loss (single batch): 0.030697\n",
      "\t partial train loss (single batch): 0.033315\n",
      "\t partial train loss (single batch): 0.035132\n",
      "\t partial train loss (single batch): 0.031402\n",
      "\t partial train loss (single batch): 0.033723\n",
      "\t partial train loss (single batch): 0.033600\n",
      "\t partial train loss (single batch): 0.033682\n",
      "\t partial train loss (single batch): 0.034642\n",
      "\t partial train loss (single batch): 0.031424\n",
      "\t partial train loss (single batch): 0.032604\n",
      "\t partial train loss (single batch): 0.032821\n",
      "\t partial train loss (single batch): 0.033268\n",
      "\t partial train loss (single batch): 0.032906\n",
      "\t partial train loss (single batch): 0.031698\n",
      "\t partial train loss (single batch): 0.033354\n",
      "\t partial train loss (single batch): 0.032845\n",
      "\t partial train loss (single batch): 0.033807\n",
      "\t partial train loss (single batch): 0.032788\n",
      "\t partial train loss (single batch): 0.031669\n",
      "\t partial train loss (single batch): 0.033704\n",
      "\t partial train loss (single batch): 0.036302\n",
      "\t partial train loss (single batch): 0.031810\n",
      "\t partial train loss (single batch): 0.032584\n",
      "\t partial train loss (single batch): 0.033716\n",
      "\t partial train loss (single batch): 0.031781\n",
      "\t partial train loss (single batch): 0.032215\n",
      "\t partial train loss (single batch): 0.033710\n",
      "\t partial train loss (single batch): 0.031294\n",
      "\t partial train loss (single batch): 0.030361\n",
      "\t partial train loss (single batch): 0.032789\n",
      "\t partial train loss (single batch): 0.032378\n",
      "\t partial train loss (single batch): 0.031813\n",
      "\t partial train loss (single batch): 0.032553\n",
      "\t partial train loss (single batch): 0.034091\n",
      "\t partial train loss (single batch): 0.033978\n",
      "\t partial train loss (single batch): 0.032659\n",
      "\t partial train loss (single batch): 0.034590\n",
      "\t partial train loss (single batch): 0.033026\n",
      "\t partial train loss (single batch): 0.032466\n",
      "\t partial train loss (single batch): 0.033694\n",
      "\t partial train loss (single batch): 0.031414\n",
      "\t partial train loss (single batch): 0.033012\n",
      "\t partial train loss (single batch): 0.033044\n",
      "\t partial train loss (single batch): 0.032673\n",
      "\t partial train loss (single batch): 0.032677\n",
      "\t partial train loss (single batch): 0.032741\n",
      "\t partial train loss (single batch): 0.035094\n",
      "\t partial train loss (single batch): 0.034160\n",
      "\t partial train loss (single batch): 0.032685\n",
      "\t partial train loss (single batch): 0.032283\n",
      "\t partial train loss (single batch): 0.035101\n",
      "\t partial train loss (single batch): 0.033977\n",
      "\t partial train loss (single batch): 0.032537\n",
      "\t partial train loss (single batch): 0.033933\n",
      "\t partial train loss (single batch): 0.033547\n",
      "\t partial train loss (single batch): 0.033657\n",
      "\t partial train loss (single batch): 0.032761\n",
      "\t partial train loss (single batch): 0.033411\n",
      "\t partial train loss (single batch): 0.034514\n",
      "\t partial train loss (single batch): 0.032987\n",
      "\t partial train loss (single batch): 0.033696\n",
      "\t partial train loss (single batch): 0.033104\n",
      "\t partial train loss (single batch): 0.030525\n",
      "\t partial train loss (single batch): 0.033747\n",
      "\t partial train loss (single batch): 0.034479\n",
      "\t partial train loss (single batch): 0.030481\n",
      "\t partial train loss (single batch): 0.032875\n",
      "\t partial train loss (single batch): 0.033552\n",
      "\t partial train loss (single batch): 0.033291\n",
      "\t partial train loss (single batch): 0.032110\n",
      "\t partial train loss (single batch): 0.031547\n",
      "\t partial train loss (single batch): 0.033254\n",
      "\t partial train loss (single batch): 0.031810\n",
      "\t partial train loss (single batch): 0.034012\n",
      "\t partial train loss (single batch): 0.032356\n",
      "\t partial train loss (single batch): 0.033766\n",
      "\t partial train loss (single batch): 0.034610\n",
      "\t partial train loss (single batch): 0.032176\n",
      "\t partial train loss (single batch): 0.032818\n",
      "\t partial train loss (single batch): 0.034766\n",
      "\t partial train loss (single batch): 0.032836\n",
      "\t partial train loss (single batch): 0.033503\n",
      "\t partial train loss (single batch): 0.028909\n",
      "\t partial train loss (single batch): 0.033593\n",
      "\t partial train loss (single batch): 0.031164\n",
      "\t partial train loss (single batch): 0.032549\n",
      "\t partial train loss (single batch): 0.033299\n",
      "\t partial train loss (single batch): 0.033082\n",
      "\t partial train loss (single batch): 0.032405\n",
      "\t partial train loss (single batch): 0.033009\n",
      "\t partial train loss (single batch): 0.034565\n",
      "\t partial train loss (single batch): 0.032818\n",
      "\t partial train loss (single batch): 0.030414\n",
      "\t partial train loss (single batch): 0.032334\n",
      "\t partial train loss (single batch): 0.034950\n",
      "\t partial train loss (single batch): 0.033240\n",
      "\t partial train loss (single batch): 0.032446\n",
      "\t partial train loss (single batch): 0.033366\n",
      "\t partial train loss (single batch): 0.034895\n",
      "\t partial train loss (single batch): 0.032427\n",
      "\t partial train loss (single batch): 0.032205\n",
      "\t partial train loss (single batch): 0.033736\n",
      "\t partial train loss (single batch): 0.031085\n",
      "\t partial train loss (single batch): 0.031141\n",
      "\t partial train loss (single batch): 0.031739\n",
      "\t partial train loss (single batch): 0.032022\n",
      "\t partial train loss (single batch): 0.033479\n",
      "\t partial train loss (single batch): 0.034982\n",
      "\t partial train loss (single batch): 0.034721\n",
      "\t partial train loss (single batch): 0.032351\n",
      "\t partial train loss (single batch): 0.030724\n",
      "\t partial train loss (single batch): 0.033277\n",
      "\t partial train loss (single batch): 0.031528\n",
      "\t partial train loss (single batch): 0.031591\n",
      "\t partial train loss (single batch): 0.034044\n",
      "\t partial train loss (single batch): 0.031046\n",
      "\t partial train loss (single batch): 0.032783\n",
      "\t partial train loss (single batch): 0.032039\n",
      "\t partial train loss (single batch): 0.033082\n",
      "\t partial train loss (single batch): 0.032462\n",
      "\t partial train loss (single batch): 0.031745\n",
      "\t partial train loss (single batch): 0.032628\n",
      "\t partial train loss (single batch): 0.033558\n",
      "\t partial train loss (single batch): 0.031581\n",
      "\t partial train loss (single batch): 0.032699\n",
      "\t partial train loss (single batch): 0.033088\n",
      "\t partial train loss (single batch): 0.033523\n",
      "\t partial train loss (single batch): 0.030834\n",
      "\t partial train loss (single batch): 0.033354\n",
      "\t partial train loss (single batch): 0.032952\n",
      "\t partial train loss (single batch): 0.034242\n",
      "\t partial train loss (single batch): 0.031473\n",
      "\t partial train loss (single batch): 0.032959\n",
      "\t partial train loss (single batch): 0.034132\n",
      "\t partial train loss (single batch): 0.034592\n",
      "\t partial train loss (single batch): 0.031810\n",
      "\t partial train loss (single batch): 0.035857\n",
      "\t partial train loss (single batch): 0.030604\n",
      "\t partial train loss (single batch): 0.033335\n",
      "\t partial train loss (single batch): 0.031971\n",
      "\t partial train loss (single batch): 0.030631\n",
      "\t partial train loss (single batch): 0.031133\n",
      "\t partial train loss (single batch): 0.033151\n",
      "\t partial train loss (single batch): 0.032477\n",
      "\t partial train loss (single batch): 0.032287\n",
      "\t partial train loss (single batch): 0.034129\n",
      "\t partial train loss (single batch): 0.031577\n",
      "\t partial train loss (single batch): 0.033047\n",
      "\n",
      "\n",
      "\t VALIDATION - EPOCH 10/10 - loss: 0.032616\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Training cycle\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "\n",
    "    ### Training (use the training function)\n",
    "    train_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_dataloader, \n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim)\n",
    "\n",
    "\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=test_dataloader, \n",
    "        loss_fn=loss_fn)\n",
    "    # Print Validationloss\n",
    "    print('\\n\\n\\t VALIDATION - EPOCH %d/%d - loss: %f\\n\\n' % (epoch + 1, num_epochs, val_loss))\n",
    "\n",
    "    ### Plot progress\n",
    "    # Get the output of a specific image (the test image at index 0 in this case)\n",
    "    img = test_dataset[0][0].unsqueeze(0).to(device)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        rec_img  = decoder(encoder(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot reconstructed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAG8CAYAAADD1QQVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyX0lEQVR4nO3de5ykeV0f+s+3u2d6ZnZmdpa977DsLheBLCKIySKXaJS8iB4wBINy0QAxQY85STwxN00ixMRz9JxciMZI1phDfCl4iwoaiGISojnqwQURiFyWyy6wCwszs8vszs50T3f/zh9Vw/YO3TPdv3qmq3v2/X695jUzVfWp36+eeur51reep56q1loAAACY3My0JwAAAHCx0GABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBdtAVd1RVS+d9jwAuDhV1d+vqndOex69quqGqnrFtOfRo0aeVlV/cxOZg1X1Ny7kvLhwNFhc1KrqVVX1/qp6oKo+W1X/pqoOnSfz96vqlzZ4/xu+ba/xnP/FhRwDYLsbfxB1oqpOVtVnquoHpj2ns1XVfFW9oKr2XKD7/9NVdf0FuN/nVNVnh77foVTV7iS/mOT3xv9vVXV/Vd03/vOu8eWvq6rTVXW8qu6tqndU1Y2r7ue87wmq6ilV9StVdXQ8xqer6j+Nr/vaqjq1xvzO9yHpJ5P8QpIfWSP7qPF491fVH1fVc5KktXY8yS1V9aJNLSy2BQ0WF62q+t4k/yTJ/5bk0iTPSHJNkneMN9Zn336mqmZaaz/cWvuLGxljM7ft1Vr77tba37qQYwDsEN/RWtub5NuSvLaq/tS0J3SWa5P8WpJDa11ZVbsmvP+fTvLsCe/jS7TW/kdr7Zqh73dAfz3Jb7fWPr7qsj/bWjs0/rN6PfgvrbWDSR6XZFeS1yUbe09QVU/OqIn7YJIvS3IwyXOTvHXC+T8pyWvWue5fJ7knyRVJ/naSX66q/ePrvi/Jv1zrPQvbmwaLi1JVHUzyj5N8d2vtv7fWlltrdyV5eZLDSb59fLvXVdVvVNWPJbk3yVXjy/7zqvt6XlV9dPxp12ur6lRVfe2q/Orbtqp6RVX9zvhTtR9fdd2zq+r/G3+qdmdVPX+Dj+WNVfWG8b9vHI/xoqp6X1V9oaq+u6r+fFV9rKo+V1XfsCr7E1X1qfHt/mNVzY0vr6r6Z+M5vq+qXl9Vd6zKXT/+5O9oVf2nqrpss88BwIXSWvsvSY5n9KY0SVJVL6mqj4z3bv3dVZdXVX1vVd1eVceq6kOrrntVVX24qo5U1X+uqptWXXdHVf31qvr18bbyl6tqdnzdwap62/j+PldVTx/H/tv47w9X1dvHt33j+M/PJ/nMqsvesGqsN1TVG1f9//lV9Z5xvfhEVT2jqv5Dksck+anxfM7M5W+Mb/PJqvq2Vfext6reXKO9Ob+XUcOwpjprz0xVvbOq/klV/dy4fvzGuP781njsn1x12zP16L6q+mBVfeWq685VP2eq6oeq6q7xc/O89eaX5C8n+Y/nuP5LtNaOJfn9JAdqg+8Jkrw2o0bu+1trR9vIJ1pr/3YzY68xlxNrXV5V1yT5i0n+cWttobX2tiT/M8lfGuc+mdE6c65lwzakweJi9awk80netvrC1tqpJL+Zh2+s/nSS9yc51Fp72CES443yL2T0qdf1ST6b5HyfJH1fkr+S5CuTfHdVPXF8+ckkr2ytXZbkLUn+4eYf1hd9Z5Kvy+jTrn+W5MVJviLJrUm+f9Xt3pFRUf0TSb4xydeML/+2JN+S5Knj+/li4a2qyqiQ/XqSq5Icy/gTQIBpGzc3/zDJF5K8c3zZU5P8RJLnZ7Rn4u+sanpemdF2+eWttUdlvP2vqq9J8s8zeoN7TZLfTfKrVbX6vdHfTfJPk9yQ5M/modrxl5LsyajBe0KS28eX/5nx309srX3Dqvt5cZKfSXLlBh7fl2W0x+RfJbk8ydOTfKS19sqMDjX7jvFem+WqekFGe3f+ZJJvSPKGqrp6fFd/J8mjk1yXUSPx5PONfZa/muTfZdTUPSejmvC9Sb4qyV+pqseNb3ckyQuSPCrJh5P87+PHcb76+d1Jvjaj5ffXkvxsVc2vsTyuzqiG/c+NTryqZqvq2Rk99/8xG39P8GeSXNDD/s9yc5L7WmufWXXZB5I8bdX/35fRuscOosHiYnVFkiOtteU1rvtsVn3qmeS21tqtrbW2xm1fkNHG7z+01k6PP8VaPM/Yf6+19uHxoQyLGRXutNbe01o788npe86aw2b9tdbakYyK+lyS72ytPZDko6vvt7X2y621k+NP6u5Zdd23J/mp1tonx/fz06vu+09kVNDfMF5+v5BR4QaYtn+f5GhGb5yf1Vp7cHz5tyd523hvw91JfjsPbbe+PclPtNb+IElaa59edfkvtNbe31pbSvLDGR3KdaYxS5Ifbq39fmvtC0nuznh7nuTzGX2o9YLW2hfG299zeUtr7dfWqTNn+9Yk7xrXnZXW2n2ttfvXue0rk7y5tXaktfY/M2pwvn583SuS/Hhr7YHW2icy+mBvM25trf3W+LF/Psm/aK39UWvto+Prr0i+eHjhJ1trK0nem4fqzPnq5yszqkMPttZ+M6Na9ow15nF9kpXxd5JWe0c99B2s56y6/OszqnevT/J9rbU3ZePvCS7PeC/jOcyvGve+qrovoya0x1UZ7Yld7fj48jPuzWgZsIPMTXsCcIEcSXJlVc2NC+dq14yvP2PNXfdj1ye5Y5NjH13175akkmR86MkPZXT8/BVJPrXJ+13twVX/Xhl/CndGffEfVd+Z0XHf14/HPHPd9Uk+sc59H04ym+Se0c6szCRZmGCuAEP5yxntybgtyWMzanqS0XbrxVX1TeP/70py5/jf1yb52Br3dTjjkyYkSWttsaqOjS9/9/jiNbfnrbWfr9HJE366qj6S5Ftaa3ecY97nqjNnW2++azmc5H+ph842tzsP7SV7TJK7NjHu2R48z//P1LanJfnBjI7auDzJfx9ff776eTjJj9ZDJ3Gaz8MbizOWx+PUWQ3qn22t/f4at/8vrbU/d9ZlG31PcCyjPX7nstBaO7T6gtWH2G/S5zL6ntdql2bUIJ4xk/EyYOewB4uL1e9l1BS8YPWFVbU3o0NIfmuD93MsqzZ+48PnklGh3axfSvJARrv+/1pHflOq6oVJ/s8kfzOjAvLJVVc/7HFltC0485g+keR0ksPjw1AOttbOe1gLwFZorb0/yY8m+Xf10Nn6PpHkl1ad9OCSVScHuiPJ49e4q09n1MwkGZ0BMKPD3D69xm3XmsePJLkpyVKS/+PMxWfu7nzxPPw92KNX/Xu9+Z7Jrb7vT2S0Z+nM497XWvtX4+uOZ52TbQxl/D2w38zoqIwn5uFnyTtf/fxEku9ZNfe9rbVfXWOYT2W0rA5NMNWNvif470leNsE4m/WBJJeOv4t1xlMz2hN4xqPy8PrNDqDB4qI0PqThHyf51zU6re1sVR1O8rMZ7f7/mQ3e1W8m+fKq+pPjQv5/Z/TJ6PkOE1zL45L8j4w28n86yWU1PunEBfK4jA59+IOMjpm/LA99svn2JK+oqn1V9fiMvsu1mCSttdsz+qL2j1XVgRp50gWcJ8BmvS7J3oxOSpCMviv0wqr6pvHJE/bWQ6fn/rdJ/teqemaSVNUTa3Q2v59O8pIanZZ7LqPvaX0oD39zu6aqemZVPSaj74HdmdGHUsloj9dKRtvcc7knyVeOTxzxQ0luWXXdzyR5WlV9x7h2XbnqDfjnz7rvHx8/tmeP53VgXOuSUdPw6qqaG38f7dXne1wdDmRUV/5rRnvPbslDdeZ89fPHknx/VT1lPPcrqupL9mCND2N/T0aNR5dNvCf4wSTPqqofO/Ndthr9/tY/6B37PPO6J6PTz7+2Rqf4f2FG35Vb/R7laRnVbHYQDRYXrdba/5VREX5DRp/kvTujovb1rbUNHfLWWrszyXcl+dWMvt/0wYyK57GOKf3djI4Jv218f/dmdFKKC+VnxmPck9Fj+EdJXjcuZv8io08P78qowLw1D39ML83oU9KPjvM/egHnCbAp47Oy/Y0kf7uqnj7+jtE3ZnSSn6MZNUrfOL7tmZMKvXn8fZmfSbKrtfY7Sf5Wkl/O6MOoZyZ50fi7ROfzuIz2dhzL6LC2fzAe64EkP5DkZ6rqXB/k/URGzcYfZVRTvniGvPF3yP5cRkc6HMvog7kbxlf/QJKXVdUnx7f93Ywap38zfmx/mIeatb+T0V6fIxntYdvsd7DOq7V2X0ZNya9l1FD9eJJrq+q156ufrbWfy+goi1+qqnsz+t7cenvubs2oLq22+jtY963VnJ011/O+JxjvHX1ORnsmPzJepr+R0WF73arqSEYnCTnz/a2fW3X1X89oT+rRjL4H+BfOfOdufMKT/XnosEt2iNrY9y3hkWv8KeWZ70u9JqNCfcMGi/C2VKPf2JhvrR2t0Y8s/nySd7fWvv/cSQDYmKHq5/jMju/M6DTrHxh0ktvU+JDKtyb5l621/zrt+bA59mDB+f0/GX3i9vmMTnX7TTu5uRp7SpI/GH9q+IGMPl38oelOCYCLzCD1c5x5cUandH+kOJDkTZqrnckeLAAAgIHYgwUAADAQDRYAAMBANFgAAAADuZC/wfMlqsoXvgDYkNba+X6s9YJQq9gJHvrd3s3x3XsY1lq1aksbLAAAJjc31/cWbnl5uSs3SWPWm9VEslM5RBAAAGAgGiwAAICBTNRgVdWfqqo/qqoPVtV3DjUpABiKWgXAVproh4ar6v1JvjnJnUneleSFrbVPnuP2DooFYEOGOsmFWsXFaNeuXV0538GCYa1Vq7r3YFXV05M80Fr7SGttIclbknzrBPMDgEGpVQBstUkOEbwpyV2r/n/3+LKHqarXVNVtVXXbBGMBQA+1CoAtNeRp2meSfMk+2dbarUluTRx2AcDUqVUAXFCT7MH6RJLrVv3/cJI7JpoNAAxLrQJgS3U3WK21P0yyv6oeV1V7kvz5JL842MwAYEJqFQBbbdJDBP9qkl9JsjvJ61trd0w8IwAYlloFwJaZ6DTtmx7Mce0AbNBQp2nfLLWKncBp2ocfD3qsVauGPMkFAACb0NtEzMz0fctjZWWlKzeJ3sfYS4PFtE1ykgsAAABW0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBANFgAAAADmZv2BAAAHqlmZvo+615ZWenKtda6cpPofYy9c93q8SYxjTG58OzBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCBz054AAABbo7W25WOurKxs+Zg9qmpLc8nOWTa9prG+bQf2YAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxkbtoTAAD6VFVXbvfu3V25paWlrlyv3sc3idZaV653rrOzs125Q4cOdeWOHz/elVtZWenKJf3LpnfMmZm+/Qe98+wdbxK9y2arl+ni4mJXbpL1rfc1PDe3+bZovW2iPVgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBANFgAAAADmZv2BACAnWFmpu9z2dZaV66qunIrKytduUnG7NW7TBcWFrZ0vNnZ2a7cJGMuLS115ebm+t7enj59uis3yTrT+9rY6uexd5n2Pr7e5yLpf/33PI/rZezBAgAAGIgGCwAAYCAaLAAAgIFM9B2sqnpjkq9Ocn+StNa+aoA5AcAg1CkAttoQJ7n4ztbaOwe4HwC4ENQpALaMQwQBAAAGMmmDdV+SH6+qN1fV4waYDwAM6b6oUwBsoYkarNba97TWbk7ya0l+fa3bVNVrquq2qrptkrEAYLM2UqcStQqA4VTvD4B9yR1VfT7JU1pr95zjNsMMBsBFr7U26C++bqROjW+3Y2pV7w+c7t69uyvX+wOefmh4fbt27erKzc/Pd+Wm8WO6F/sPDU/yI8xDvQ/fqN7nsXeZnjp1qis3jR8a7nmMS0tLWVlZ+ZKFOtEerKqaHf/9lPFFRya5PwAYkjoFwFab9CyCP1VVNydpSV7WWlseYE4AMBR1CoAtNVGD1Vp71UDzAIDBqVMAbDWnaQcAABjIYCe52NBgO+iLwwBM19Anudiora5V0zh5wL59+7pyvV90X1xc7Mr1vkdZXu4/ErR3mfbau3dvV673RCW9J9WY5KQDvXPtPcnFnj17unK9j3GS9e3kyZNdud7H2DvX3vF6TzixsLDQlZsk27OdWlhYGP4kFwAAADxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxkbtoTAFjP7Oxsd3ZlZaUr11rrHrPH/Px8V25hYaEr9/jHP74rlyQf/ehHu7NcGLt27erKzc31lf/e19VWvx6Xl5e7cpPofS52797dlet9DpeWlrpyk2yP9+7d25XrXaaXXHJJV+706dNduUnWt6NHj3bleteb3tfi5Zdf3pXrrVW9z0WS3HfffV25nmWzuLi45uX2YAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxkbtoTgItFVW1pLklWVla6cocPH+7KffVXf3VX7u1vf3tX7sSJE125nWRhYWFLx/vmb/7m7uyP/MiPDDiTi880tgGttS0dc6tzMzN9nwPv2rWrKzeJ+fn5Lc1de+21XblTp0515fbs2dOVS5Lrr7++K3fVVVd15Y4fP96VO3LkSFfu/vvv78olyezsbFeut/73Po9bndu3b19XLkmuuOKKrtzHPvaxTWfWez3ZgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBA5qY9AXikW1lZ2fIxn/vc53blbrnllq7cdddd15X70R/90a7cTnLVVVd15Z7//Od35Y4fP96VY3uam+sr47Ozs125vXv3duVaa1253se3tLTUlUv6l02vAwcOdOV2797dlbvsssu6cocPH+7KJclNN93UlTt48GBXbnl5uSt35513duUWFxe7ckly9913d+V619M9e/Z05XrXm95l0zvPJPnIRz6yZWPOzKy9r8oeLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIHMTXsCcLGYnZ3tyi0tLXWP+VVf9VVduSc/+clduXvuuacr94QnPKEr9yu/8itduSQ5duxYV27v3r1duTvvvLMrd/nll3flDh482JX79Kc/3ZXj/KqqK9e77Uj619dLL720K7eystKVO3nyZFdu3759XbnWWlcuSS655JKu3PLyclfucY97XFfu6quv7sodPny4K3fFFVd05SbJHjhwoCt39OjRLR3v7rvv7sol/a//3vVt//79XbnrrruuK9dr165d3dneZfPxj39805n1tvv2YAEAAAxEgwUAADCQTTVYVfWoCzURAJiUOgXAtG2owaqqr6uq30ny+aqaG1+2p6p+qao+WFW/WlV9B4IDwITUKQC2i43uwfrjJN9w1u2/J8kft9aenOS2JH9r2KkBwIapUwBsCxtqsFprn22tPXDWxS9L8rPjf78pycuHnBgAbJQ6BcB2Mclp2m9Kctf433eP//8lquo1SV4zwTgA0GNDdSpRqwAYzlC/gzWTZM0fnWit3Zrk1iSpqv4fpgCAfuvWqUStAmA4k5ym/RNJzvzq2OEkd0w8GwAYjjoFwJabpMF6c5KXjv/9iiQ/N/l0AGAw6hQAW26jp2l/WVXdNv7v71fVK5P8qyRPr6oPJnlakn9+YaYIAOemTgGwXWzoO1ittTdn9Eng2f7CsNMBgM1TpwDYLiY5RBAAAIBVhjqLIFw0Zmb6PndYWlrqyl1yySVduSR5yUte0pVbWFjoyu3Zs6crd+DAga5cVXXlkv7nsXfMm2++uSv3qU99qit37733duXm5mz2L5Tedad3XZ2G5eXlrlzvenf55Zd35SZx7bXXduV27drVlXvuc5/blZufn+/KXXPNNV253u140j/X3vVmdna2K9f7Wrz00ku7ckny2Mc+tiu3uLjYlTt16lRX7tGPfnRXrlfvOpMkR48e7cr1vB9bb13bOVt1AACAbU6DBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADGRu2hNgMlXVlWutdeVmZvp78t4xe3Ozs7NdueXl5a5cr+/6ru/qzn72s5/typ06daord+ONN3bl9uzZ05W75557unJJ//O/srLSlTtx4kRXbnFxsSt38ODBrtz8/HxXLkkuueSSrlzvspmmubnNl8fdu3d3jbVv376uXJLs37+/K/fYxz62K9e7fVxaWurKPelJT+rK9b4+kuTw4cNduRtuuKEr1/ua7H0uDh061JXbu3dvVy7pf+/Quz3ufYy9r8Xe92JJcvLkya5c7/bmgQce6Mr11vHe137vPJP+ZXPttdduOvOxj31szcvtwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABjI3LQncLGpqq5ca21Lc71WVla2dLwkmZ2d7cotLy8PPJNze9nLXtaVu+aaa7rHfM973tOV27VrV1fu0KFDXbmjR4925Y4dO9aVS5IrrriiK3fgwIGuXO962mtmpu/zsX379nWP+YQnPKEr9973vrd7zGmoqq7XyP79+7vG630uJxmzdxtw0003deV6X48333xzV27Pnj1duSS59NJLu3K7d+/uyvU+/wsLC125XouLi93Z3vdGvcu0V+97qknWt97X8Pz8fFfu4MGDXbmlpaWu3MmTJ7tyk3j84x/flXvnO9+56cx664w9WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAOZm/YELjattS0db2amr0fuzS0vL3flkv5lM8mYPV796ld35Z74xCd25T71qU915ZLkiiuu6MpVVVdu7969Xbm77rqrK3fgwIGuXJKsrKx05R588MGu3J49e7pyvc/FVm9rkuT5z39+V+69733vsBO5wGZmZrJv375N56699tqu8fbv39+VS5JHP/rRXbnrrruuK/eVX/mVXbnrr7++K9e7bObn57tySXL69Omu3NLSUleut8ZNo4732rVrV1eu9zHOzs5uaa738SWTras9eh9j73Nx6tSprtwky+Uxj3lMV66njq+3XOzBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCBz057AhTQzs/X9Y2utK1dVXbmVlZUtzU3Ddddd15V78Ytf3JXbu3dvV+7222/vyu3fv78rlyTz8/Nducsvv7wrt7i42JXrfV3s27evKzeJ5eXlrtzCwsKWjnfixImu3CSv/Wc/+9nd2Z1kdnY2l1566aZzT3jCE7rG27VrV1dukjF7t6s33nhjV+7QoUNdud5txyTLdPfu3V253jre+xh7tzmzs7Ndubm5/reMvbWjtx73Pv+9NefAgQNduWSy5dqj97k4ffp0V653mU7y3mjPnj1duSH7BnuwAAAABqLBAgAAGMimGqyqetSFmggATEqdAmDaNtRgVdXXVdXvJPl8Vc2NL/vaqjpSVbeN/7zggs4UANahTgGwXWz0m3V/nOQbktx/1uW/3lp71aAzAoDNU6cA2BY21GC11j6b9J8hBwAuJHUKgO1ikpNcLCb5mqr67ap6yXo3qqrXnDk8Y4KxAGCzNlSnkofXqp30MxYAbD/dJ99vrf1ukpuq6oYkv1lVd40vO/t2tya5NUmqqu/HHgBgkzZap8a3/WKtmp+fV6sA6Dbxadpba3cmeWuS504+HQAYljoFwFbqbrCqanb8964kX53k9qEmBQCTUqcAmIaNnqb9Zau+Q/X7VfXKJN9UVX+Y5A+S/L+ttV++UJMEgHNRpwDYLjZ6FsE3J3nzGlf9yrDTAYDNU6cA2C4m/g4WAAAAI91nEew1Ozu76czy8nLXWDvpVLutbe1Jq6688squ3A033NA95pOe9KSu3LXXXtuVW1xc7ModP368K3fo0KGu3MGDB7tySbJr166u3Pz8fFeu9zXVu970Pr4kue+++7pyp0+f7sr1LpuZmb7PuU6ePNmV69kGn3H//Wf/hu/G3HzzzZvOfOxjH+saawi7du3KVVddtencnj17usbbu3dvVy7p335cdtllXbnebceBAwe6cr2/azZJTd29e3dXrve13LvNeeCBB7pyvevMJNuO3vWt9/nvfQ7n5vreFk9Sq3q3q5deemlXrnfZ9D4XvbVxku3i7bf3fd22Zzu13uvCHiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBzG31gMvLy1s21tVXX92dveGGG7pyl1xyyZbm9u7d25W76aabunL79u3ryiXJ6dOnu3IPPPBAV25mpu/zg0svvbQr1/tcLC0tdeWS/ufjwQcf7MotLCx05Xbv3t2V+8xnPtOVS/qfx95leu+993bl9u/f35W77LLLunInTpzoyiXJNddc05W7/PLLN5258847u8YaQlVlbm7z5bF3+fSuA0ly5ZVXduV66+OjHvWorlzvY+ytG73buEn0rDNJsrKy0pXrrTk9r8ckOXnyZFcuSVprXbne57GqunK961tvbZxkzOPHj3flFhcXu3KnTp3qyvU+973v/ZL+5/+ee+7ZdGa9588eLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIHMTXsCG/G85z2vK3fdddd1j3n69Omu3FVXXdWVm5np63VXVla6cr2P7/777+/KJcn+/fu7ctdcc01Xrqq6cvPz8125e++9tyvX+9wn/ct0dna2K3fixImuXO9684UvfKErl/S/Frda73rT+9rfu3dvVy5Jdu/e3ZVbWlradKa11jXWEJaXl7vW2aNHj3aNd+rUqa5cklx55ZVdud71p3fbcfDgwa5c77ajd1uV9NeOhYWFLc31PsZjx4515XqXyySWl5e7cr3L5vjx41253tdF0v/879mzpys3N9f31r93m9y7bHrfpybJPffc05XrqcfrraP2YAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxkbisHO3jwYJ75zGduOvcd3/EdXeN96EMf6solyWc+85mu3PHjx7tys7OzXbnFxcUtHW8S999/f1du9+7dXbnl5eWu3MGDB7tyVdWV27t3b1cuSVZWVrpyu3bt6spdc801Xbmrr766K3fzzTd35ZL+x7jVr40TJ0505fbt29eVO3XqVFcu6Z/r5z73uU1nlpaWusYawtLSUo4ePbrp3L333ts1Xu/rOEkeeOCBrlxvrepdf44cOdKVW1hY6MpNskx7x2ytdeV6l2nvtmpmpu+z9d5anPS/V5mb63ub2rt+975POX36dFcu6d/W9dbj3tdG73PY+7qYZH3rfT56tqfrvde0BwsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBzG3lYCdOnMi73vWuTeee+cxndo335V/+5V25JHn2s5/dne2xtLTUlbv//vu7cseOHdvSXJJ84Qtf6Mrt3r27K1dVXbnLL7+8K/fEJz6xK7dv376uXJIcPHiwK9da68p9xVd8RVfufe97X1fujjvu6MolyfOe97yu3Pz8fFeud5n26t1m3HXXXd1jHj9+vCu3f//+TWdmZqb3+d/S0lKOHj266dwHP/jBrvEuu+yyrlySnDx5sit33333deV6t6u9r4/e7fHCwkJXLunfBjz44INdud5l+sADD3TlVlZWunI9r+Mzep//xcXFrlzP6zdJPv7xj3flel+HSf/z+KxnPasr17tMe18Xvc/FJDXgbW97W1dubm7zbdF6r197sAAAAAaiwQIAABiIBgsAAGAgG2qwquotVfXuqvpgVb10fNkVVfVb48t+sqo0awBMjVoFwHaw0ULz2tbaM5L8uST/tqr2JPmnSd7UWntykkrysgs0RwDYCLUKgKnbUIPVWnvv+O87k5xOcijJtyT5ufFN3pTk5cNPDwA2Rq0CYDvY1PkIq+qFST6UZDHJSmvtzDlJ705y0zqZ1yR5zfjf/TMFgA1QqwCYpg03WFX19CSvTfKiNa6eSbLmjxy01m5NcmuSzM3Nbe0PxQDwiDJErZqZmVGrAOi2oQarqm5K8lNJvqm19unxZVVVe1trJ5McTnLHBZslAJyHWgXAdnDe72DV6FiJNyf5vjMFa+wXk7xk/O9X5KFj3AFgS6lVAGwXGznJxVOS3JLkh6rqtvGfq5L8oySvrqoPJVlK8rMXcJ4AcC5qFQDbwnkPEWytvT+jU9uu5c8MOx0A2Dy1CoDtwg8uAgAADGRTp2mf1PLycu67775N537wB39w+Mmcx/79+7tyt9xyS1fuy77sy7pyz3rWs7pyN954Y1fuqU99alcuSS655JKuXO8pk1vrOxHYyspKV+7YsWNdufe///1duSR5xzve0ZV7+9vf3pU7depUV24a3vrWt3blHvOYx3Tljhw50pW7//77tzS3tLTUlUuShYWFrtztt9++ZWMNZXl5edOZ2dnZCzCTc+tdDz71qU915Xq3jydOnOjKHThwoCvXu/1PkiuvvLIr11sDemvjzEzfZ+Qf+MAHunK9jy9JTp482ZW76667unJzc31vb++9996u3Pz8fFdukuxnPvOZrlzv+rZ3796uXO+2fJKfy+hdNj3r2+nTp9e83B4sAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgVRrbesGq9q6wQDY0VprNY1xZ2Zm2tzc3KZzhw8f7hrv0KFDXbkkOXXqVFfu0ksv7crt27evK3f8+PGu3MGDB7tyi4uLXbkkueSSS7pyR48e7cpddtllW5r7/Oc/35U7cuRIVy5JlpaWunLHjh3rHrPHyZMnu3Lz8/PdY15++eVduV27dnXlZmdnu3K961vV1m/Ge9ebD3/4w5vOLCwsZGVl5UsepD1YAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA6nW2tYNVrV1gwGwo7XWahrjVlWr2vzQl1xySdd4e/bs6colycGDB7tyMzN9n6+eOnWqK3f8+PGu3MrKSldukvc2kzwfPQ4cONCVO3ToUFfu7rvv7sqdOHGiK5cki4uLXbne53+rzc/Pd2f37dvXlet9Dfcu055tYpLs3bu3K9f7+JJkYWGhK/e5z31u05nl5eU1a5U9WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAOp1trWDVa1dYMBsKO11moa4/bWqpmZvs8sd+3a1ZVLkoMHD3bllpeXu3ILCwtduZMnT3blepfpTjI7O9uVm5+f78otLi5uaW4SW/kedZLxep/DSbJVfZvH3td+73aqdz2d5LV/4sSJrtzp06c3nVlZWVmzVl38Wy4AAIAtosECAAAYiAYLAABgIBosAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGUq21rRusausGA2BHa63VNMbd6lo1M9P/WWdvtje3vLy8pbmdpGprV9e5ubmu3MrKypbmkmQr32vuNFu93my1aTy+3vVtgtyXPEh7sAAAAAaiwQIAABiIBgsAAGAgG2qwquotVfXuqvpgVb10fNmrquruqrpt/OcZF3aqALA+tQqA7WBDJ7moqqe11t5bVTckeV+Sq5O8NMmNrbXXbXgwJ7kAYIM2e5KLnVqrnOTi4uAkF+tzkov1OcnF8HbMSS5aa+8d/31nktNJDnXNAAAuELUKgO1gUx9hVdULk3yotfbZJCeTvKKq3lFVX3eOzGvOHJox4VwB4LzUKgCmacO/g1VVT0/yk0le1Fr79KrLn5rkbUme01q74zz3YR8xABvS8ztYO7FWOUTw4uAQwfU5RHB9DhEc3o45RLCqbkryUzmrYI3v9H1Jfi/JLV2zAoABqFUAbAfnbbBq1Hq+Ocn3nfVp4Oz47/1Jnp7k9gs1SQA4F7UKgO3ivIcIVtWXZ3Q2pnevuvgbk3xLklcnmU3yxtba6887mEMEAdigzRwiuJNrlUMELw4OEVyfQwTX5xDB4W2HQwQ3/B2sIWiwANionu9gDUGDtT4N1vo0WOvTYK1PgzW87dBg9W/VAQAAeBgNFgAAwED69i8DAIOYxuFTWz1m7yGJW32oT7L1hzT1jreTDrvbSc9/j0kO893quW71+raT1tMh2YMFAAAwEA0WAADAQDRYAAAAA9FgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBANFgAAAAD0WABAAAMRIMFAAAwkGqtbd1gVVs3GAA7WmutpjHuTqpVVX2LqDe3le8ZJrFT5pl4Ds9lJ82VYfWu30n/ejM7O7vpzPLy8pq1yh4sAACAgWiwAAAABqLBAgAAGIgGCwAAYCAaLAAAgIFosAAAAAaiwQIAABiIBgsAAGAgGiwAAICBaLAAAAAGosECAAAYiAYLAABgIBosAACAgcxt8XhHkty5znVXjK/nS1k2a7Nc1mfZrM+yWd92WjY3THHsHVOrWmtbmjuHbbVctplzLptt9BxOg/VmfY/oZXOO9fuCLZfl5eWe2Jq1qrbLC7SqbmutfdW057EdWTZrs1zWZ9msz7JZn2VzfpbR2iyX9Vk267Ns1mfZrG2nLBeHCAIAAAxEgwUAADCQ7dRg3TrtCWxjls3aLJf1WTbrs2zWZ9mcn2W0NstlfZbN+iyb9Vk2a9sRy2XbfAcLAABgp9tOe7AAAAB2NA0WO05VPWrac9iOLBeA7cH2eH2WDY8E26LBqqo/VVV/VFUfrKrvnPZ8touqemNVfbiqbquq26Y9n2mrqq+rqt9J8vmqmhtftqeqfmm87vxqVe2d8jS33DrL5Wur6siZdaeqXjDlaU5FVb2lqt49Xj9eOr7siqr6rfFlP1lV22I7uNXWWTavqqq7V603z5j2PLcLdWpt6tTDqVPrU6vWp1atb6fWqm3xHayqen+Sb87ohx3fleSFrbVPTndW01dVb0zyxtbaO6c8lW2hqq5J8kCS+5Psaq0tVdXfT7KvtfYDVfUPk7TW2g9NdaJbbJ3l8rVJXtVae9UUpzZ1VfW01tp7q+qGJO9LcnWS1yd5V2vt31fVv0vy31prPzvNeU7DOsvmpUlubK29bqqT24bUqbWpUw+nTq1PrVqfWrW+nVqrpt4NV9XTkzzQWvtIa20hyVuSfOuUp8U21Fr7bGvtgbMuflmSMxucNyV5+dbOavrWWS4kaa29d/z3nUlOJzmU5FuS/Nz4Jo/IdSZZd9mwBnWKjVKn1qdWrU+tWt9OrVVTb7CS3JTkrlX/v3t8Gcl9SX68qt5cVY+b9mS2qdXrj3XnIYtJvqaqfruqXjLtyUxbVb0wyYcyWi4rrbUHx1c94teZM8umtfbZJCeTvKKq3lFVXzflqW0n6tT67os6dT7q1PrUqlXUqvXttFo1N+0JrGEmyfSPW9wGWmvfkyRV9fIkv57kyVOd0PZn3Rlrrf1ukpvGu9R/s6ruGl/2iDPe+/DaJC9a4+pH9Dpz9rJprf18kp+vqqcmeVtVPae1dsf0ZrhtPaLXm9XUqU2z7qyiVj1ErVrfTqxV22EP1ieSXLfq/4eT3DGdqWxPrbU3Jbmiqq6e9ly2odXrj3XnLONd6m9N8txpz2UaquqmJD+V5EWttU+31o6NLv7il8wfsevM2ctm9XWttfcl+b0kt0xjbtuQOnUe6tQ5qVPnoVapVevZqbVq6g1Wa+0Pk+yvqsdV1Z4kfz7JL055WttCVc2O/37K+KIjU5zOdvXmjL7smCSvyEPHKz+irVp3diX56iS3T3dGW6+qKqP14/vO2ij/YpIzh6I8IteZ9ZbNqvVmf5Kn5xG43qxFnVqfOrUh6tQ61Cq16lx2cq3aLmcRvCXJTybZneT1rbU3THlK28L47Ew3Z7Rb+Ptba7813RlNV1W9LMn3JnlGkncn+bEkv5DRlz+flOTDSV6+6pjlR4R1lsvxJD+QpJL8Rmvt701vhtNRVV+e0RmH3r3q4m/M6PX0C0muTfI/krymtbay9TOcnnMsm29J8uoksxmdGe71Wz+77UmdWps69XDq1PrUqrWpVevbybVqWzRYAAAAF4OpHyIIAABwsdBgAQAADESDBQAAMBANFgAAwEA0WAAAAAPRYAEAAAxEgwUAADAQDRYAAMBA/n8Y/X9bLW93RAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plot the reconstructed image\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "axs[0].imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "axs[0].set_title('Original image')\n",
    "axs[1].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "axs[1].set_title('Reconstructed image (EPOCH %d)' % (epoch + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using grid search to optimize hypermeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnet = NeuralNetClassifier(\\n    AutoEncoder,    \\n    max_epochs=50,\\n    lr=0.1,\\n    criterion = torch.nn.CrossEntropyLoss(),\\n    # Shuffle training data on each epoch\\n    iterator_train__shuffle=True,\\n    verbose=False,\\n)\\nnet.fit(batch_data, batch_labels)\\n\\n\\n#https://nbviewer.org/github/skorch-dev/skorch/blob/master/notebooks/Basic_Usage.ipynb#Usage-with-sklearn-GridSearchCV\\n#\\nnet.set_params(train_split=False, verbose=0)\\nparams = {\\n    'lr': [5e-4, 5e-3],\\n    'encoded_space_dim' : [2,10]\\n}\\ngs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)\\ngs.fit(batch_data, batch_labels)\\nprint(gs.best_score_, gs.best_params_)\\n\\n\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "net = NeuralNetClassifier(\n",
    "    AutoEncoder,    \n",
    "    max_epochs=50,\n",
    "    lr=0.1,\n",
    "    criterion = torch.nn.CrossEntropyLoss(),\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    verbose=False,\n",
    ")\n",
    "net.fit(batch_data, batch_labels)\n",
    "\n",
    "\n",
    "#https://nbviewer.org/github/skorch-dev/skorch/blob/master/notebooks/Basic_Usage.ipynb#Usage-with-sklearn-GridSearchCV\n",
    "#\n",
    "net.set_params(train_split=False, verbose=0)\n",
    "params = {\n",
    "    'lr': [5e-4, 5e-3],\n",
    "    'encoded_space_dim' : [2,10]\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)\n",
    "gs.fit(batch_data, batch_labels)\n",
    "print(gs.best_score_, gs.best_params_)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save figures and network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figures\n",
    "os.makedirs('autoencoder_progress_%d_features' % encoded_space_dim, exist_ok=True)\n",
    "fig.savefig('autoencoder_progress_%d_features/epoch_%d.jpg' % (encoded_space_dim, epoch + 1))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Save network parameters\n",
    "torch.save(encoder.state_dict(), 'encoder_params.pth')\n",
    "torch.save(decoder.state_dict(), 'decoder_params.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:04<00:00, 2470.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enc. Variable 0</th>\n",
       "      <th>Enc. Variable 1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.217023</td>\n",
       "      <td>15.852659</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.767122</td>\n",
       "      <td>-11.892781</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.816082</td>\n",
       "      <td>13.898494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.385921</td>\n",
       "      <td>18.012415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.200367</td>\n",
       "      <td>1.760135</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-34.499191</td>\n",
       "      <td>7.485009</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>21.634312</td>\n",
       "      <td>17.180569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5.927335</td>\n",
       "      <td>7.073632</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>45.668102</td>\n",
       "      <td>24.377134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-4.324656</td>\n",
       "      <td>19.535452</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Enc. Variable 0  Enc. Variable 1  label\n",
       "0           -4.217023        15.852659      9\n",
       "1            5.767122       -11.892781      2\n",
       "2           36.816082        13.898494      1\n",
       "3           33.385921        18.012415      1\n",
       "4            2.200367         1.760135      6\n",
       "...               ...              ...    ...\n",
       "9995       -34.499191         7.485009      9\n",
       "9996        21.634312        17.180569      1\n",
       "9997         5.927335         7.073632      8\n",
       "9998        45.668102        24.377134      1\n",
       "9999        -4.324656        19.535452      5\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load network parameters\n",
    "encoder.load_state_dict(torch.load('encoder_params.pth'))\n",
    "decoder.load_state_dict(torch.load('decoder_params.pth'))\n",
    "\n",
    "\n",
    "### Get the encoded representation of the test samples\n",
    "encoded_samples = []\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "\n",
    "# Convert to a dataframe\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show latent space structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if encoded_space_dim == 2:\n",
    "    # Generate a new sample\n",
    "    custom_encoded_sample = [-2, 22.0]\n",
    "    encoded_value = torch.tensor(custom_encoded_sample).float().unsqueeze(0).to(device)\n",
    "\n",
    "    # Decode sample\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_img  = decoder(encoded_value)\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(generated_img.squeeze().cpu().numpy(), cmap='gist_gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f92b4423d60>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "encoded_samples_reduced_PCA = pca.fit_transform(encoded_samples)\n",
    "encoded_samples_reduced_PCA\n",
    "plt.scatter(encoded_samples_reduced_PCA[:,0], encoded_samples_reduced_PCA[:,1], c=encoded_samples.label.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement variational autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "#loss_fn = torch.nn.MSELoss()\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,dataloader):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        data = data.cpu()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader):\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            data = data.cpu()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taomenglu/.local/share/virtualenvs/DeepLearningClassHW-5_10-iC_/lib/python3.8/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 545.323364\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 282.815918\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 276.359772\n",
      "====> Epoch: 1 Average loss: 303.9762\n",
      "====> Test set loss: 277.2506\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 284.089325\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 269.712708\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 273.045105\n",
      "====> Epoch: 2 Average loss: 271.0017\n",
      "====> Test set loss: 269.4538\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 265.204010\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 278.186218\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 261.157837\n",
      "====> Epoch: 3 Average loss: 266.5206\n",
      "====> Test set loss: 267.2958\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 264.697968\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 269.951141\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 270.793640\n",
      "====> Epoch: 4 Average loss: 264.3965\n",
      "====> Test set loss: 265.2496\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 265.421112\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 262.483490\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 261.489319\n",
      "====> Epoch: 5 Average loss: 262.9387\n",
      "====> Test set loss: 263.9515\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 264.779236\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 261.658234\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 259.408325\n",
      "====> Epoch: 6 Average loss: 261.7257\n",
      "====> Test set loss: 262.9444\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 262.838928\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 256.382080\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 262.009277\n",
      "====> Epoch: 7 Average loss: 260.9965\n",
      "====> Test set loss: 262.5656\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 266.239624\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 262.951355\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 267.226471\n",
      "====> Epoch: 8 Average loss: 260.2276\n",
      "====> Test set loss: 261.4719\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 259.241089\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 261.486359\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 270.173187\n",
      "====> Epoch: 9 Average loss: 259.5615\n",
      "====> Test set loss: 261.7557\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 259.176697\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 261.575287\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 256.120758\n",
      "====> Epoch: 10 Average loss: 259.1642\n",
      "====> Test set loss: 261.3449\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 251.576614\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 257.251953\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 259.962341\n",
      "====> Epoch: 11 Average loss: 258.8245\n",
      "====> Test set loss: 260.5423\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 259.881470\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 257.552856\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 259.050476\n",
      "====> Epoch: 12 Average loss: 258.4492\n",
      "====> Test set loss: 260.4984\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 264.557861\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 254.514923\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 263.478088\n",
      "====> Epoch: 13 Average loss: 258.0230\n",
      "====> Test set loss: 259.8804\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 247.810852\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 249.373138\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 255.692200\n",
      "====> Epoch: 14 Average loss: 257.7119\n",
      "====> Test set loss: 259.9016\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 259.136566\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 259.326599\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 267.667114\n",
      "====> Epoch: 15 Average loss: 257.4606\n",
      "====> Test set loss: 258.9615\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 261.403473\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 261.619690\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 248.912811\n",
      "====> Epoch: 16 Average loss: 257.1634\n",
      "====> Test set loss: 258.8660\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 256.729370\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 258.057343\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 255.457443\n",
      "====> Epoch: 17 Average loss: 257.0063\n",
      "====> Test set loss: 259.0319\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 253.988510\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 252.652115\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 252.817978\n",
      "====> Epoch: 18 Average loss: 256.5721\n",
      "====> Test set loss: 258.5078\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 264.237488\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 264.321991\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 256.628326\n",
      "====> Epoch: 19 Average loss: 256.5258\n",
      "====> Test set loss: 258.8081\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 254.095856\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 256.235504\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 255.445374\n",
      "====> Epoch: 20 Average loss: 256.4093\n",
      "====> Test set loss: 259.2832\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 255.513840\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 259.701263\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 260.241180\n",
      "====> Epoch: 21 Average loss: 256.0704\n",
      "====> Test set loss: 258.3748\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 255.259689\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 252.004608\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 251.042694\n",
      "====> Epoch: 22 Average loss: 255.7685\n",
      "====> Test set loss: 258.8495\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 253.356735\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 257.554535\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 254.038696\n",
      "====> Epoch: 23 Average loss: 255.8915\n",
      "====> Test set loss: 257.9251\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 255.106567\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 254.322876\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 248.559723\n",
      "====> Epoch: 24 Average loss: 255.4902\n",
      "====> Test set loss: 258.0751\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 251.340073\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 257.188324\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 253.246017\n",
      "====> Epoch: 25 Average loss: 255.3085\n",
      "====> Test set loss: 257.5547\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 248.345093\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 253.591614\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 254.133347\n",
      "====> Epoch: 26 Average loss: 254.9309\n",
      "====> Test set loss: 257.4063\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 253.216278\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 257.957886\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 249.673431\n",
      "====> Epoch: 27 Average loss: 254.8199\n",
      "====> Test set loss: 257.4452\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 254.213379\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 251.095428\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 256.860229\n",
      "====> Epoch: 28 Average loss: 254.5799\n",
      "====> Test set loss: 256.8374\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 258.242859\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 260.297394\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 247.402405\n",
      "====> Epoch: 29 Average loss: 254.4567\n",
      "====> Test set loss: 257.7505\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 252.304916\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 255.316330\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 254.069397\n",
      "====> Epoch: 30 Average loss: 254.5578\n",
      "====> Test set loss: 257.2415\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 241.390457\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 254.009628\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 265.504089\n",
      "====> Epoch: 31 Average loss: 254.3851\n",
      "====> Test set loss: 256.6395\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 244.903702\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 264.746399\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 254.905624\n",
      "====> Epoch: 32 Average loss: 253.9777\n",
      "====> Test set loss: 256.4029\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 256.572266\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 257.117950\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 260.156067\n",
      "====> Epoch: 33 Average loss: 253.9209\n",
      "====> Test set loss: 256.5016\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 249.755844\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 246.055847\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 245.975464\n",
      "====> Epoch: 34 Average loss: 253.7615\n",
      "====> Test set loss: 256.9445\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 256.721405\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 250.781967\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 253.651382\n",
      "====> Epoch: 35 Average loss: 253.7543\n",
      "====> Test set loss: 256.2995\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 264.687622\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 253.731064\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 256.991852\n",
      "====> Epoch: 36 Average loss: 253.5816\n",
      "====> Test set loss: 256.4204\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 251.835205\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 257.730865\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 251.886322\n",
      "====> Epoch: 37 Average loss: 253.6453\n",
      "====> Test set loss: 256.6103\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 256.473175\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 252.647568\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 253.578354\n",
      "====> Epoch: 38 Average loss: 253.5700\n",
      "====> Test set loss: 256.0134\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 251.981583\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 257.450684\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 255.642242\n",
      "====> Epoch: 39 Average loss: 253.2194\n",
      "====> Test set loss: 256.1048\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 253.695541\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 255.663940\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 256.364594\n",
      "====> Epoch: 40 Average loss: 253.2520\n",
      "====> Test set loss: 255.4850\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 258.062744\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 262.347015\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 260.640137\n",
      "====> Epoch: 41 Average loss: 253.1073\n",
      "====> Test set loss: 256.4528\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 257.533752\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 259.146332\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 254.595306\n",
      "====> Epoch: 42 Average loss: 253.7442\n",
      "====> Test set loss: 255.9329\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 252.333679\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 257.125366\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 252.363876\n",
      "====> Epoch: 43 Average loss: 253.2124\n",
      "====> Test set loss: 256.3462\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 250.692383\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 255.103104\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 249.252899\n",
      "====> Epoch: 44 Average loss: 253.2952\n",
      "====> Test set loss: 255.4218\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 252.331970\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 255.613983\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 261.221222\n",
      "====> Epoch: 45 Average loss: 252.5519\n",
      "====> Test set loss: 255.6957\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 254.509781\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 253.740952\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 256.658936\n",
      "====> Epoch: 46 Average loss: 252.7350\n",
      "====> Test set loss: 255.1254\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 245.726700\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 249.265747\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 246.789062\n",
      "====> Epoch: 47 Average loss: 252.7879\n",
      "====> Test set loss: 255.3029\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 247.841156\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 252.545135\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 251.880112\n",
      "====> Epoch: 48 Average loss: 252.4547\n",
      "====> Test set loss: 255.3291\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 256.581726\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 252.610794\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 247.116409\n",
      "====> Epoch: 49 Average loss: 252.3476\n",
      "====> Test set loss: 254.7575\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 256.930542\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 253.520538\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 259.439636\n",
      "====> Epoch: 50 Average loss: 252.5325\n",
      "====> Test set loss: 254.9499\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch,train_dataloader)\n",
    "    test(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce8923c4b0d9de410a564c705388b4ca73268c38e87210713ee5d3f095c270d9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('DeepLearningClassHW-5_10-iC_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
